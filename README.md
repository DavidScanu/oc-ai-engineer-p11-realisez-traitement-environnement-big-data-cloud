# Projet 11 : RÃ©alisez un traitement dans un environnement Big Data sur le Cloud

# Projet Big Data - Classification de Fruits

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.x-E25A1C?logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![AWS](https://img.shields.io/badge/AWS-EMR%20%7C%20S3-FF9900?logo=amazonaws&logoColor=white)](https://aws.amazon.com/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.16-FF6F00?logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![Dataset](https://img.shields.io/badge/Dataset-Fruits--360-green?logo=kaggle&logoColor=white)](https://www.kaggle.com/datasets/moltean/fruits)

> ğŸ“ OpenClassrooms â€¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | ğŸ‘‹ *Ã‰tudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)

---

<p align="center">
  <img src="images/p11-cover-large-01.jpg" alt="Couverture : Pipeline Big Data Fruits - MobileNetV2 + PCA" style="max-width:100%;height:auto;">
</p>

## ğŸ“‹ Description

Projet de mise en place d'une **architecture Big Data dans le cloud** pour le traitement d'images de fruits. DÃ©veloppÃ© pour **"Fruits!"**, une start-up AgriTech qui dÃ©veloppe des robots cueilleurs intelligents pour prÃ©server la biodiversitÃ© des fruits.

Ce projet implÃ©mente un **pipeline PySpark distribuÃ© dans le cloud** sur **AWS EMR** pour :
- Extraire des features d'images avec **MobileNetV2** (Transfer Learning)
- RÃ©duire les dimensions avec **PCA** (1280 â†’ 50 composantes)
- Traiter jusqu'Ã  **~67,000 images** en mode distribuÃ©

---

## ğŸ¯ Livrables finaux

### âœ… Code & Scripts

| Livrable | Localisation | Description |
|----------|--------------|-------------|
| **Notebook local corrigÃ© et fonctionnel** | [p11-david-scanu-local-development.ipynb](notebooks/p11-david-scanu-local-development.ipynb) | DÃ©veloppement local du pipeline PySpark avec broadcast TensorFlow et PCA |
| **Script PySpark** | [process_fruits_data.py](traitement/etape_2/scripts/process_fruits_data.py) | Pipeline PySpark production-ready (MobileNetV2 + PCA) |
| **Bootstrap EMR** | [install_dependencies.sh](traitement/etape_2/scripts/install_dependencies.sh) | Installation TensorFlow, scikit-learn |
| **Scripts automatisation** | [traitement/etape_2/scripts/](traitement/etape_2/scripts/) | 11 scripts bash (create, monitor, submit, etc.) |
| **Configuration** | [config.sh](traitement/etape_2/config/config.sh) | Config centralisÃ©e (EMR, Spark, S3) |
| **PrÃ©sentation** | [Google Slides](https://docs.google.com/presentation/d/1YH2OK8qeV0dBRjcsCU09T9dZZ977ExN2fQvkeF7-Iv0/edit?usp=sharing) | Support de prÃ©sentation du projet |

### ğŸ“¦ Stockage S3

#### Structure des donnÃ©es

```
s3://oc-p11-fruits-david-scanu/
â”‚
â”œâ”€â”€ data/raw/Training/            # Images source (67,000 images)
â”‚   â”œâ”€â”€ Apple Braeburn/
â”‚   â”‚   â”œâ”€â”€ 0_100.jpg
â”‚   â”‚   â”œâ”€â”€ 1_100.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Banana/
â”‚   â””â”€â”€ ... (224 classes)
â”‚
â”œâ”€â”€ read_fruits_data/              # Outputs Ã‰tape 1
â”‚   â”œâ”€â”€ scripts/                   # Scripts uploadÃ©s
â”‚   â”œâ”€â”€ logs/emr/                  # Logs EMR
â”‚   â””â”€â”€ output/etape_1/            # MÃ©tadonnÃ©es + stats
â”‚
â””â”€â”€ process_fruits_data/           # Outputs Ã‰tape 2 â­
    â”œâ”€â”€ scripts/                   # Scripts uploadÃ©s
    â”œâ”€â”€ logs/emr/                  # Logs EMR
    â””â”€â”€ outputs/                   # RÃ©sultats (features, PCA, etc.)
        â”œâ”€â”€ output-mini/
        â”œâ”€â”€ output-apples/
        â””â”€â”€ output-full/
            â”œâ”€â”€ features/          # Features 1280D
            â”œâ”€â”€ pca/               # PCA 50D
            â”œâ”€â”€ metadata/          # Labels
            â””â”€â”€ model_info/        # Variance PCA
```

#### Exemples de chemins

- **Image** : `s3://oc-p11-fruits-david-scanu/data/raw/Training/Apple Braeburn/0_100.jpg`
- **Features** : `s3://oc-p11-fruits-david-scanu/process_fruits_data/outputs/output-full/features/`
- **PCA** : `s3://oc-p11-fruits-david-scanu/process_fruits_data/outputs/output-full/pca/`

### Architecture GDPR-compliant

- RÃ©gion `eu-west-1` 

---

## ğŸ“Š Jeu de donnÃ©es

**Fruits-360 Dataset**

- **CrÃ©ateur** : Mihai Oltean (2017-)
- **Taille** : 155,491 images rÃ©parties en 226 classes (version 100x100)
- **Format** : JPG, 100x100 pixels (standardisÃ©)
- **Contenu** : Fruits, lÃ©gumes, noix et graines avec de multiples variÃ©tÃ©s
  - 29 types de pommes
  - 12 variÃ©tÃ©s de cerises
  - 19 types de tomates
  - Et bien d'autres...
- **MÃ©thode de capture** : Images capturÃ©es par rotation (20s Ã  3 rpm) sur fond blanc
- **Licence** : CC BY-SA 4.0

**Sources** :
- [Kaggle](https://www.kaggle.com/datasets/moltean/fruits)
- [TÃ©lÃ©chargement direct](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P8/fruits.zip)

---

## ğŸ“– Ã‰tapes du projet

Ce projet a Ã©tÃ© dÃ©veloppÃ© en plusieurs Ã©tapes pour migrer progressivement le traitement des donnÃ©es du local vers le cloud AWS EMR.

### ğŸ”¬ Ã‰tape 0 : DÃ©veloppement local et amÃ©lioration du notebook de l'alternant

**Objectif** : Comprendre et amÃ©liorer le code de base avant la migration cloud

- ğŸ““ **Notebook local fonctionnel crÃ©Ã©** : [p11-david-scanu-local-development.ipynb](notebooks/p11-david-scanu-local-development.ipynb)
- âœ… **Analyse du travail de l'alternant** : Ã‰tude du notebook PySpark existant : [P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb](notebooks/alternant/P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb)
- âœ… **Corrections et amÃ©liorations** :
  - Ajout du broadcast des poids TensorFlow (absent dans le notebook de l'alternant)
  - ImplÃ©mentation de la rÃ©duction PCA avec MLlib (manquante)
  - Tests locaux du pipeline complet
  - Validation de la logique avant dÃ©ploiement cloud
- ğŸ¯ **Livrable** : Notebook fonctionnel avec pipeline end-to-end testÃ© localement

> ğŸ’¡ **Approche** : Cette Ã©tape a permis de valider la logique mÃ©tier en local (Spark standalone) avant de passer Ã  l'infrastructure cloud coÃ»teuse.

---

### âœ… Ã‰tape 1 : Validation de l'infrastructure cloud

**Objectif** : Valider la lecture/Ã©criture S3 et tester le cluster EMR avec un pipeline simple

- âœ… **Pipeline de test** :
  - Lecture de ~67,000 images depuis S3
  - Extraction des mÃ©tadonnÃ©es (path, label, classe)
  - Calcul de statistiques par classe
  - Ã‰criture des rÃ©sultats sur S3 (CSV)
- ğŸ—ï¸ **Infrastructure AWS dÃ©ployÃ©e** :
  - CrÃ©ation du cluster EMR (Master + 2 Core nodes)
  - Configuration S3 (bucket, IAM roles, security groups)
  - Scripts d'automatisation bash (11 scripts)
  - Bootstrap action pour installer les dÃ©pendances Python
- ğŸ¯ **Validation** :
  - âœ… Lecture/Ã©criture S3 fonctionnelle
  - âœ… PySpark distribuÃ© opÃ©rationnel
  - âœ… Bootstrap action testÃ©e
  - âœ… Gestion des coÃ»ts (auto-terminaison)

**RÃ©sultats** :
- DurÃ©e : ~2-5 min (67,000 images)
- Output : MÃ©tadonnÃ©es + statistiques CSV
- CoÃ»t : ~0.05â‚¬

> ğŸ’¡ **Importance** : Cette Ã©tape a validÃ© l'infrastructure AWS avant d'ajouter la complexitÃ© du traitement TensorFlow + PCA.

**Documentation** : [traitement/etape_1/docs](traitement/etape_1/docs)

---

### ğŸ¯ Ã‰tape 2 : Pipeline complet Feature Extraction + PCA

**Objectif** : ImplÃ©menter le **pipeline big data complet** avec TensorFlow et rÃ©duction de dimensions PCA

- ğŸ§  **Feature Extraction** :
  - MobileNetV2 prÃ©-entraÃ®nÃ© (Transfer Learning)
  - Broadcast des poids TensorFlow (~14 MB) vers tous les workers
  - Pandas UDF pour traitement distribuÃ©
  - Extraction de 1280 features par image
- ğŸ“‰ **RÃ©duction PCA** :
  - PCA avec MLlib (1280 â†’ 50 dimensions)
  - Variance conservÃ©e : **83-93%** (selon le mode)
  - Sauvegarde du modÃ¨le PCA pour rÃ©utilisation
- ğŸ¯ **Modes de traitement validÃ©s** :
  - **MINI** (300 images) : 3min 34s, 92.93% variance, ~0.50â‚¬
  - **APPLES** (6,404 images) : ~20-25 min, 83.40% variance, ~0.40â‚¬
  - **FULL** (67,692 images) : 83 min (1h23), 71.88% variance, ~1.60â‚¬ âœ…

#### Architecture du pipeline

```
Images S3 (JPG)
    â”‚
    â”œâ”€> [1] Chargement (binaryFile)
    â”‚
    â”œâ”€> [2] MobileNetV2 Feature Extraction
    â”‚       â€¢ Broadcast des poids (~14 MB)
    â”‚       â€¢ Pandas UDF (traitement distribuÃ©)
    â”‚       â€¢ Output: 1280 features par image
    â”‚
    â”œâ”€> [3] PCA (MLlib)
    â”‚       â€¢ RÃ©duction: 1280 â†’ 50 dimensions
    â”‚       â€¢ Variance conservÃ©e: 92.93%
    â”‚
    â””â”€> [4] Sauvegarde S3 (Parquet + CSV)
            â€¢ features/ (1280D)
            â€¢ pca/ (50D)
            â€¢ metadata/ (labels)
            â€¢ model_info/ (variance)
```

#### Optimisations appliquÃ©es

- âœ… **Broadcast TensorFlow** : -90% transferts rÃ©seau
- âœ… **Pandas UDF + Arrow** : 10-100Ã— plus rapide
- âœ… **Parquet** : -50% stockage vs CSV
- âœ… **PCA 50D** : -96% dimensions (1280 â†’ 50)

#### Documentation 

- **Documentation complÃ¨te** : [traitement/etape_2/docs](traitement/etape_2/docs)
- **Quickstart** : [QUICKSTART.md](traitement/etape_2/QUICKSTART.md)
- **Readme** : [README.md](traitement/etape_2/docs/README.md)
- **Workflow** : [WORKFLOW.md](traitement/etape_2/docs/WORKFLOW.md)
- **Architecture** : [ARCHITECTURE.md](traitement/etape_2/docs/ARCHITECTURE.md)

---

## RÃ©sultats validÃ©s

### ğŸ¯ DÃ©marche incrÃ©mentale

Le pipeline a Ã©tÃ© validÃ© avec une approche progressive en 3 modes :

- **MINI** (300 images) : Validation rapide du pipeline (~3-5 min, ~0.50â‚¬)
- **APPLES** (6,404 images) : Test sur un sous-ensemble homogÃ¨ne (~20-25 min, ~0.40â‚¬)
- **FULL** (67,000 images) : Production complÃ¨te avec tous les fruits (~2-3h, ~1.60â‚¬)

Cette dÃ©marche permet de :
- Valider rapidement les modifications (mode MINI)
- Tester la scalabilitÃ© sur des donnÃ©es rÃ©elles (mode APPLES)
- Passer en production en toute confiance (mode FULL)

### ğŸ“¦ Outputs gÃ©nÃ©rÃ©s

Le pipeline PySpark gÃ©nÃ¨re plusieurs types de fichiers structurÃ©s :

```
s3://oc-p11-fruits-david-scanu/process_fruits_data/outputs/output-{mode}/
â”œâ”€â”€ features/          # Features brutes (1280D) - MobileNetV2
â”‚   â”œâ”€â”€ parquet/       # Format optimisÃ© pour Spark
â”‚   â””â”€â”€ csv/           # Format lisible
â”œâ”€â”€ pca/               # Features rÃ©duites (50D) - PCA
â”‚   â”œâ”€â”€ parquet/       # Compression ~92-96% vs features brutes
â”‚   â””â”€â”€ csv/
â”œâ”€â”€ metadata/          # Chemins S3 + labels des images
â”œâ”€â”€ model_info/        # Informations PCA et variance par composante
â”‚   â”œâ”€â”€ model_info_*   # JSON avec variance totale et config
â”‚   â””â”€â”€ variance_*     # CSV avec variance de chaque composante
â””â”€â”€ errors/            # Log des erreurs (absent si 100% succÃ¨s)
```

**Tailles typiques** :
- **MINI** : ~6.4 MB total (features: 5.9 MB, pca: 456 KB)
- **APPLES** : ~125-145 MB total (features: 115-130 MB, pca: 8-10 MB)
- **FULL** : ~1.7-2.0 GB total (features: 1.5-1.8 GB, pca: 150-200 MB) âœ…

### ğŸ’¾ TÃ©lÃ©chargement des rÃ©sultats

Pour rÃ©cupÃ©rer les rÃ©sultats en local :

```bash
cd traitement/etape_2
./scripts/download_results.sh [mode]
```

**Exemples** :
```bash
./scripts/download_results.sh mini     # TÃ©lÃ©charge rÃ©sultats MINI
./scripts/download_results.sh apples   # TÃ©lÃ©charge rÃ©sultats APPLES
./scripts/download_results.sh          # Utilise le dernier mode exÃ©cutÃ©
```

Les rÃ©sultats sont sauvegardÃ©s dans `traitement/etape_2/outputs/output-{mode}/` avec la mÃªme structure qu'en S3.

### ğŸ“Š Comparaison des modes

| MÃ©trique | MINI | APPLES | FULL |
|----------|------|--------|------|
| **Images traitÃ©es** | 300 (100%) | 6,404 (100%) | **67,692 (100%)** âœ… |
| **Classes traitÃ©es** | ~3-5 variÃ©tÃ©s | ~29 variÃ©tÃ©s pommes | **131 classes** âœ… |
| **Temps d'exÃ©cution** | 3min 34s | ~20-25 min | **83 min (1h23)** âœ… |
| **DÃ©bit** | ~84 img/min | ~260-320 img/min | **~814 img/min** âœ… |
| **Variance PCA (50 comp.)** | **92.93%** | **83.40%** | **71.88%** âœ… |
| **Taux d'erreur** | 0% | 0% | **0%** âœ… |
| **CoÃ»t estimÃ©** | ~0.50â‚¬ | ~0.40â‚¬ | **~1.60â‚¬** âœ… |
| **Documentation des rÃ©sultats** | [MINI](traitement/etape_2/outputs/output-mini/RESULTATS-MINI.md) | [APPLES](traitement/etape_2/outputs/output-apples/RESULTATS-APPLES.md) | **[FULL](traitement/etape_2/outputs/output-full/RESULTATS-FULL.md)** âœ… |
| **Notebook** | [Notebook](traitement/etape_2/outputs/output-mini/resultats-mini.ipynb) | [Notebook](traitement/etape_2/outputs/output-apples/resultats-apples.ipynb) | **[Notebook](traitement/etape_2/outputs/output-full/resultats-full.ipynb)** âœ… |

**Observations** :
- **ScalabilitÃ© exceptionnelle** : 226Ã— plus d'images (vs MINI) mais seulement 23Ã— plus de temps
- **DÃ©bit impressionnant** : Ã—9.7 entre MINI et FULL grÃ¢ce au parallÃ©lisme Spark
- La variance PCA est plus faible sur FULL (71.88%) car **diversitÃ© maximale** avec 131 classes de fruits
- **Pipeline production-ready validÃ©** : 0 erreur sur 67,692 images en 83 minutes
- CoÃ»t trÃ¨s raisonnable : ~1.60â‚¬ pour traiter l'ensemble complet du dataset

> ğŸš€ **Accomplissement majeur** : Pipeline production-ready avec support multi-mode, toutes les optimisations Big Data et conformitÃ© GDPR.

---

## ğŸ¯ Objectifs rÃ©alisÃ©s

- âœ… **Pipeline PySpark complet** avec broadcast des poids TensorFlow
- âœ… **RÃ©duction de dimension PCA** implÃ©mentÃ©e avec MLlib
- âœ… **Migration cloud AWS** (EMR + S3)
- âœ… **ConformitÃ© GDPR** (rÃ©gion eu-west-1)
- âœ… **Architecture production-ready** avec scripts d'automatisation

> âš ï¸ **Note** : Pas d'entraÃ®nement de modÃ¨le. L'objectif est de mettre en place les briques de traitement **scalables**.

## ğŸ› ï¸ Stack technique

| Technologie | Version | Usage |
|-------------|---------|-------|
| **PySpark** | 3.5.x | Traitement distribuÃ© |
| **AWS EMR** | 7.11.0 | Cluster Spark managÃ© |
| **AWS S3** | - | Stockage cloud (GDPR) |
| **TensorFlow** | 2.16.1 | MobileNetV2 (features) |
| **Python** | 3.10+ | Scripting & PySpark |
| **scikit-learn** | 1.4.0 | Validation PCA |

## ğŸ“ Structure du projet

```
oc-ai-engineer-p11-realisez-traitement-environnement-big-data-cloud/
â”‚
â”œâ”€â”€ traitement/                    # ğŸ¯ Pipeline de traitement (PRINCIPAL)
â”‚   â”œâ”€â”€ etape_1/                   # Ã‰tape 1: Read & Validate Data
â”‚   â”‚   â”œâ”€â”€ config/                # Configuration centralisÃ©e
â”‚   â”‚   â”œâ”€â”€ scripts/               # Scripts bash + PySpark
â”‚   â”‚   â”œâ”€â”€ docs/                  # Documentation complÃ¨te
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ etape_2/                   # Ã‰tape 2: Feature Extraction + PCA â­
â”‚       â”œâ”€â”€ config/                # Configuration (m5.2xlarge, PCA 50)
â”‚       â”œâ”€â”€ scripts/               # 11 scripts bash + process_fruits_data.py
â”‚       â”œâ”€â”€ docs/                  # README, WORKFLOW, ARCHITECTURE, RESULTATS
â”‚       â”œâ”€â”€ outputs/               # RÃ©sultats tÃ©lÃ©chargÃ©s (local)
â”‚       â”œâ”€â”€ logs/                  # Logs EMR tÃ©lÃ©chargÃ©s (local)
â”‚       â””â”€â”€ QUICKSTART.md          # DÃ©marrage rapide
â”‚
â”œâ”€â”€ notebooks/                     # Notebooks de dÃ©veloppement local
â”‚   â”œâ”€â”€ p11-emr-fruits-pca.ipynb   # Notebook fonctionnel (base Ã©tape 2)
â”‚   â””â”€â”€ alternant/                 # Travail de l'alternant (rÃ©fÃ©rence)
â”‚
â”œâ”€â”€ scripts/                       # Scripts utilitaires
â”‚   â””â”€â”€ aws_audit.sh               # Audit coÃ»ts AWS
â”‚
â””â”€â”€ README.md                      # Ce fichier
```

### ğŸ—‚ï¸ Navigation rapide

| Dossier | Description | Liens |
|---------|-------------|-------|
| **[traitement/etape_1/](traitement/etape_1/)** | Pipeline de lecture S3 (validation) | [README](traitement/etape_1/docs/README.md) |
| **[traitement/etape_2/](traitement/etape_2/)** | Pipeline MobileNetV2 + PCA â­ | [README](traitement/etape_2/docs/README.md) â€¢ [QUICKSTART](traitement/etape_2/QUICKSTART.md) |
| **[notebooks/](notebooks/)** | Dev local + rÃ©fÃ©rence alternant | [Notebook PCA](notebooks/p11-emr-fruits-pca.ipynb) |

---

## âš¡ DÃ©marrage rapide

### PrÃ©requis

- AWS CLI configurÃ©
- AccÃ¨s S3 : `oc-p11-fruits-david-scanu`
- ClÃ© SSH EMR : `emr-p11-fruits-key-codespace`

### ExÃ©cution Ã‰tape 2 (7 commandes)

```bash
cd traitement/etape_2

# 1. VÃ©rifications
./scripts/verify_setup.sh

# 2. Upload scripts S3
./scripts/upload_scripts.sh

# 3. CrÃ©er cluster (~10-15 min)
./scripts/create_cluster.sh

# 4. Surveiller
./scripts/monitor_cluster.sh

# 5. Soumettre job
./scripts/submit_job.sh  # Choisir mode: mini/apples/full

# 6. TÃ©lÃ©charger rÃ©sultats
./scripts/download_results.sh

# 7. âš ï¸ ARRÃŠTER LE CLUSTER
./scripts/terminate_cluster.sh
```

**DÃ©tails** : [QUICKSTART.md](traitement/etape_2/docs/QUICKSTART.md)

> âš ï¸ **Gestion des coÃ»ts** : Toujours terminer le cluster aprÃ¨s usage !

---

## ğŸ’° CoÃ»ts AWS (rÃ©els)

| Phase | DurÃ©e | CoÃ»t |
|-------|-------|------|
| **Ã‰tape 1** (validation) | ~5 min | ~0.05â‚¬ |
| **Ã‰tape 2 (MINI)** | ~30 min | ~0.50â‚¬ |
| **Ã‰tape 2 (APPLES)** | ~30 min | ~0.40â‚¬ |
| **Ã‰tape 2 (FULL)** | ~1h40 | ~1.60â‚¬ âœ… |
| **TOTAL projet** | - | **< 3â‚¬** âœ… |

**Auto-terminaison** : 4h idle timeout (sÃ©curitÃ© anti-coÃ»ts)

### Script d'audit des coÃ»ts AWS 

Un script d'audit rapide est disponible pour lister les ressources AWS susceptibles d'engendrer des coÃ»ts (instances EC2 actives, volumes EBS, Elastic IP, buckets S3, NAT Gateway, RDS, EMR, etc.). Le script est non-destructif : il se contente de lister et rÃ©sumer les ressources.

FichierÂ : `scripts/aws_audit.sh`

- Actions effectuÃ©es : vÃ©rifications EC2 (par rÃ©gion), EBS, snapshots, AMIs privÃ©es, Elastic IPs, ELB, NAT Gateways, RDS, EKS, EFS, EMR, S3 buckets (taille via aws s3 ls --recursive --summarize), option Cost Explorer (--costs).
- Options : `--region`, `--all-regions`, -`-costs`, `--quiet`.

Usage rapide :

```bash
# rendre exÃ©cutable (une seule fois)
chmod +x scripts/aws_audit.sh

# scan rapide pour la rÃ©gion eu-west-1
./scripts/aws_audit.sh --region eu-west-1

# scan toutes les rÃ©gions (long)
./scripts/aws_audit.sh --all-regions

# inclure Cost Explorer (requiert permissions & activation)
./scripts/aws_audit.sh --region eu-west-1 --costs
```

Remarques :
- Le calcul de la taille des buckets S3 via `aws s3 ls --recursive --summarize` peut Ãªtre lent pour les gros buckets (par ex. `mlflow-artefact-store`).
- L'option `--costs` utilise l'API Cost Explorer (rÃ©gion `us-east-1`) et nÃ©cessite que le service soit activÃ© et que l'utilisateur ait la permission `ce:GetCostAndUsage`.
- Le script n'effectue aucune suppression ; les actions de nettoyage restent manuelles.

### Obtenir coÃ»ts par service sur 30 jours (Cost Explorer) :

```bash
aws ce get-cost-and-usage \
  --time-period Start=$(date -d '30 days ago' +%Y-%m-%d),End=$(date +%Y-%m-%d) \
  --granularity MONTHLY --metrics UnblendedCost \
  --group-by Type=DIMENSION,Key=SERVICE \
  --region us-east-1 \
  --query "ResultsByTime[0].Groups[].{Service: Keys[0],Amount: Metrics.UnblendedCost.Amount}" \
  --output table
```

---

## ğŸ“š Ressources & Documentation

### Documentation du projet

| Resource | Lien |
|----------|------|
| **Documentation** | [traitement/etape_2/docs/](traitement/etape_2/docs/) |
| **Quickstart** | [traitement/etape_2/QUICKSTART.md](traitement/etape_2/QUICKSTART.md) |
| **RÃ©sultats validÃ©s** | [traitement/etape_2/docs/RESULTATS.md](traitement/etape_2/docs/RESULTATS.md) |

| Document | Lien | Contenu |
|----------|------|---------|
| **README Ã‰tape 2** | [README.md](traitement/etape_2/docs/README.md) | Documentation complÃ¨te |
| **Quickstart** | [QUICKSTART.md](traitement/etape_2/docs/QUICKSTART.md) | DÃ©marrage en 7 commandes |
| **Workflow** | [WORKFLOW.md](traitement/etape_2/docs/WORKFLOW.md) | ProcÃ©dure dÃ©taillÃ©e |
| **Architecture** | [ARCHITECTURE.md](traitement/etape_2/docs/ARCHITECTURE.md) | Architecture technique |

### RÃ©fÃ©rences externes

- [AWS EMR Getting Started](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html)
- [Troubleshoot Python Libraries on EMR](https://repost.aws/fr/knowledge-center/emr-troubleshoot-python-libraries)
- [Notebook alternant (rÃ©fÃ©rence)](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P8/P8_Mode_ope%CC%81ratoire.zip)
- [Fruits-360 Dataset (Kaggle)](https://www.kaggle.com/datasets/moltean/fruits)

---

## ğŸ“… Dates

- **DÃ©but** : 24 Octobre 2024
- **Ã‰tape 1 validÃ©e** : 13 Novembre 2024
- **Ã‰tape 2 validÃ©e** : 21 Novembre 2024
- **Mode FULL validÃ©** : 25 Novembre 2024 âœ…

---

## ğŸ† Accomplissements

- âœ… **Pipeline PySpark** complet et scalable
- âœ… **Architecture AWS** production-ready (EMR + S3)
- âœ… **Broadcast TensorFlow** pour optimisation rÃ©seau
- âœ… **PCA MLlib** avec 92.93% de variance conservÃ©e
- âœ… **Scripts d'automatisation** (11 scripts bash)
- âœ… **Documentation exhaustive** (4 documents techniques)
- âœ… **ConformitÃ© GDPR** (rÃ©gion eu-west-1)
- âœ… **Gestion des coÃ»ts** (< 3â‚¬ total projet)

**ğŸš€ Production-ready | ğŸ“Š Big Data optimisÃ© | ğŸ” GDPR compliant**

---

## ğŸ‘¤ Auteur

> ğŸ“ OpenClassrooms â€¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | ğŸ‘‹ *Ã‰tudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)
