# Projet 11 : RÃ©alisez un traitement dans un environnement Big Data sur le Cloud

# Projet Big Data - Classification de Fruits

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python&logoColor=white)](https://www.python.org/)
[![PySpark](https://img.shields.io/badge/PySpark-3.x-E25A1C?logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![AWS](https://img.shields.io/badge/AWS-EMR%20%7C%20S3-FF9900?logo=amazonaws&logoColor=white)](https://aws.amazon.com/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.16-FF6F00?logo=tensorflow&logoColor=white)](https://www.tensorflow.org/)
[![Dataset](https://img.shields.io/badge/Dataset-Fruits--360-green?logo=kaggle&logoColor=white)](https://www.kaggle.com/datasets/moltean/fruits)

> ğŸ“ OpenClassrooms â€¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | ğŸ‘‹ *Ã‰tudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)

---

<p align="center">
  <img src="images/p11-cover-large-01.jpg" alt="Couverture : Pipeline Big Data Fruits - MobileNetV2 + PCA" style="max-width:100%;height:auto;">
</p>

## ğŸ“‹ Description

Projet de mise en place d'une **architecture Big Data dans le cloud** pour le traitement d'images de fruits. DÃ©veloppÃ© pour **"Fruits!"**, une start-up AgriTech qui dÃ©veloppe des robots cueilleurs intelligents pour prÃ©server la biodiversitÃ© des fruits.

Ce projet implÃ©mente un **pipeline PySpark distribuÃ©** sur AWS EMR pour :
- Extraire des features d'images avec **MobileNetV2** (Transfer Learning)
- RÃ©duire les dimensions avec **PCA** (1280 â†’ 50 composantes)
- Traiter jusqu'Ã  **~67,000 images** en mode distribuÃ©

---

## ğŸ“– Ã‰tapes rÃ©alisÃ©es

Ce projet a Ã©tÃ© dÃ©veloppÃ© en plusieurs Ã©tapes pour migrer progressivement le traitement des donnÃ©es du local vers le cloud AWS EMR.

### ğŸ”¬ Ã‰tape 0 : DÃ©veloppement local et amÃ©lioration du notebook de l'alternant

**Objectif** : Comprendre et amÃ©liorer le code de base avant la migration cloud

- ğŸ““ **Notebook local crÃ©Ã©** : [p11-david-scanu-local-development.ipynb](notebooks/p11-david-scanu-local-development.ipynb)
- âœ… **Analyse du travail de l'alternant** : Ã‰tude du notebook PySpark existant ([notebooks/alternant/](notebooks/alternant/))
- âœ… **Corrections et amÃ©liorations** :
  - Ajout du broadcast des poids TensorFlow (absent dans le notebook de l'alternant)
  - ImplÃ©mentation de la rÃ©duction PCA avec MLlib (manquante)
  - Tests locaux du pipeline complet
  - Validation de la logique avant dÃ©ploiement cloud
- ğŸ¯ **Livrable** : Notebook fonctionnel avec pipeline end-to-end testÃ© localement

> ğŸ’¡ **Approche** : Cette Ã©tape a permis de valider la logique mÃ©tier en local (Spark standalone) avant de passer Ã  l'infrastructure cloud coÃ»teuse.

---

### âœ… Ã‰tape 1 : Validation de l'infrastructure cloud

**Objectif** : Mettre en place et tester le cluster EMR avec un pipeline simple

- ğŸ—ï¸ **Infrastructure AWS dÃ©ployÃ©e** :
  - CrÃ©ation du cluster EMR (Master + 2 Core nodes)
  - Configuration S3 (bucket, IAM roles, security groups)
  - Scripts d'automatisation bash (11 scripts)
  - Bootstrap action pour installer les dÃ©pendances Python
- âœ… **Pipeline de test** :
  - Lecture de ~67,000 images depuis S3
  - Extraction des mÃ©tadonnÃ©es (path, label, classe)
  - Calcul de statistiques par classe
  - Ã‰criture des rÃ©sultats sur S3 (CSV)
- ğŸ¯ **Validation** :
  - âœ… Lecture/Ã©criture S3 fonctionnelle
  - âœ… PySpark distribuÃ© opÃ©rationnel
  - âœ… Bootstrap action testÃ©e
  - âœ… Gestion des coÃ»ts (auto-terminaison)

**Documentation** : [traitement/etape_1/](traitement/etape_1/)

**RÃ©sultats** :
- DurÃ©e : ~2-5 min (67,000 images)
- CoÃ»t : ~0.05â‚¬
- Output : MÃ©tadonnÃ©es + statistiques CSV

> ğŸ’¡ **Importance** : Cette Ã©tape a validÃ© l'infrastructure AWS avant d'ajouter la complexitÃ© du traitement TensorFlow + PCA.

---

### ğŸ¯ Ã‰tape 2 : Pipeline complet Feature Extraction + PCA

**Objectif** : ImplÃ©menter le pipeline big data complet avec TensorFlow et rÃ©duction de dimensions

- ğŸ§  **Feature Extraction** :
  - MobileNetV2 prÃ©-entraÃ®nÃ© (Transfer Learning)
  - Broadcast des poids TensorFlow (~14 MB) vers tous les workers
  - Pandas UDF pour traitement distribuÃ©
  - Extraction de 1280 features par image
- ğŸ“‰ **RÃ©duction PCA** :
  - PCA avec MLlib (1280 â†’ 50 dimensions)
  - Variance conservÃ©e : **83-93%** (selon le mode)
  - Sauvegarde du modÃ¨le PCA pour rÃ©utilisation
- ğŸ“¦ **Optimisations appliquÃ©es** :
  - Broadcast TensorFlow : -90% transferts rÃ©seau
  - Pandas UDF + Apache Arrow : 10-100Ã— plus rapide
  - Parquet : -50% stockage vs CSV
  - Auto-terminaison cluster (4h idle timeout)
- ğŸ¯ **Modes de traitement validÃ©s** :
  - **MINI** (300 images) : 3min 34s, 92.93% variance, ~0.50â‚¬
  - **APPLES** (6,404 images) : ~20-25 min, 83.40% variance, ~0.40â‚¬
  - **FULL** (67,000 images) : ~2-3h estimÃ©, ~1.60â‚¬

**Documentation complÃ¨te** : [traitement/etape_2/](traitement/etape_2/)

**Quickstart** : [traitement/etape_2/QUICKSTART.md](traitement/etape_2/QUICKSTART.md)

**RÃ©sultats** :
- [MINI](traitement/etape_2/outputs/output-mini/RESULTATS-MINI.md) | [Notebook](traitement/etape_2/outputs/output-mini/resultats-mini.ipynb)
- [APPLES](traitement/etape_2/outputs/output-apples/RESULTATS-APPLES.md) | [Notebook](traitement/etape_2/outputs/output-apples/resultats-apples.ipynb)

> ğŸš€ **Accomplissement majeur** : Pipeline production-ready avec support multi-mode, toutes les optimisations Big Data et conformitÃ© GDPR.

---

### ğŸ“Š Ã‰tape 3 : Documentation et livrables

**Objectif** : Documenter l'architecture, les workflows et les rÃ©sultats pour faciliter la maintenance

- ğŸ“š **Documentation technique** :
  - Architecture AWS (diagrammes, composants)
  - Workflows dÃ©taillÃ©s (crÃ©ation cluster, soumission jobs)
  - Scripts d'automatisation documentÃ©s
  - Guide de dÃ©marrage rapide (QUICKSTART.md)
- ğŸ“ˆ **RÃ©sultats et analyses** :
  - Rapport de performance (temps, coÃ»ts, dÃ©bit)
  - Analyse de variance PCA
  - ScalabilitÃ© estimÃ©e
  - Recommandations d'optimisation
- ğŸ› ï¸ **Outils de gestion** :
  - Scripts d'audit AWS ([scripts/aws_audit.sh](scripts/aws_audit.sh))
  - Monitoring des coÃ»ts
  - ProcÃ©dures de nettoyage

**Livrables finaux** :
- âœ… Code PySpark production-ready
- âœ… 11 scripts bash d'automatisation
- âœ… 4 documents techniques dÃ©taillÃ©s
- âœ… DonnÃ©es S3 (images + rÃ©sultats PCA)
- âœ… Architecture GDPR-compliant

> ğŸ“– **Documentation exhaustive** pour faciliter la reprise du projet et la mise en production.

---

## ğŸ¯ Objectifs rÃ©alisÃ©s

- âœ… **Pipeline PySpark complet** avec broadcast des poids TensorFlow
- âœ… **RÃ©duction de dimension PCA** implÃ©mentÃ©e avec MLlib
- âœ… **Migration cloud AWS** (EMR + S3)
- âœ… **ConformitÃ© GDPR** (rÃ©gion eu-west-1)
- âœ… **Architecture production-ready** avec scripts d'automatisation

> âš ï¸ **Note** : Pas d'entraÃ®nement de modÃ¨le. L'objectif est de mettre en place les briques de traitement **scalables**.

## ğŸ› ï¸ Stack technique

| Technologie | Version | Usage |
|-------------|---------|-------|
| **PySpark** | 3.5.x | Traitement distribuÃ© |
| **AWS EMR** | 7.11.0 | Cluster Spark managÃ© |
| **AWS S3** | - | Stockage cloud (GDPR) |
| **TensorFlow** | 2.16.1 | MobileNetV2 (features) |
| **Python** | 3.10+ | Scripting & PySpark |
| **scikit-learn** | 1.4.0 | Validation PCA |

## ğŸ“ Structure du projet

```
oc-ai-engineer-p11-realisez-traitement-environnement-big-data-cloud/
â”‚
â”œâ”€â”€ traitement/                    # ğŸ¯ Pipeline de traitement (PRINCIPAL)
â”‚   â”œâ”€â”€ etape_1/                   # Ã‰tape 1: Read & Validate Data
â”‚   â”‚   â”œâ”€â”€ config/                # Configuration centralisÃ©e
â”‚   â”‚   â”œâ”€â”€ scripts/               # Scripts bash + PySpark
â”‚   â”‚   â”œâ”€â”€ docs/                  # Documentation complÃ¨te
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ etape_2/                   # Ã‰tape 2: Feature Extraction + PCA â­
â”‚       â”œâ”€â”€ config/                # Configuration (m5.2xlarge, PCA 50)
â”‚       â”œâ”€â”€ scripts/               # 11 scripts bash + process_fruits_data.py
â”‚       â”œâ”€â”€ docs/                  # README, WORKFLOW, ARCHITECTURE, RESULTATS
â”‚       â”œâ”€â”€ output/                # RÃ©sultats tÃ©lÃ©chargÃ©s (local)
â”‚       â”œâ”€â”€ logs/                  # Logs EMR tÃ©lÃ©chargÃ©s (local)
â”‚       â””â”€â”€ QUICKSTART.md          # DÃ©marrage rapide
â”‚
â”œâ”€â”€ notebooks/                     # Notebooks de dÃ©veloppement local
â”‚   â”œâ”€â”€ p11-emr-fruits-pca.ipynb  # Notebook fonctionnel (base Ã©tape 2)
â”‚   â””â”€â”€ alternant/                # Travail de l'alternant (rÃ©fÃ©rence)
â”‚
â”œâ”€â”€ scripts/                       # Scripts utilitaires
â”‚   â””â”€â”€ aws_audit.sh              # Audit coÃ»ts AWS
â”‚
â””â”€â”€ README.md                      # Ce fichier
```

### ğŸ—‚ï¸ Navigation rapide

| Dossier | Description | Liens |
|---------|-------------|-------|
| **[traitement/etape_1/](traitement/etape_1/)** | Pipeline de lecture S3 (validation) | [README](traitement/etape_1/docs/README.md) |
| **[traitement/etape_2/](traitement/etape_2/)** | Pipeline MobileNetV2 + PCA â­ | [README](traitement/etape_2/docs/README.md) â€¢ [QUICKSTART](traitement/etape_2/QUICKSTART.md) â€¢ [RÃ‰SULTATS](traitement/etape_2/docs/RESULTATS.md) |
| **[notebooks/](notebooks/)** | Dev local + rÃ©fÃ©rence alternant | [Notebook PCA](notebooks/p11-emr-fruits-pca.ipynb) |

---

## ğŸš€ Pipeline rÃ©alisÃ©

### Ã‰tape 1 : Validation de l'infrastructure âœ…

**Objectif** : Valider la lecture/Ã©criture S3 et l'infrastructure EMR

- âœ… Lecture de ~67,000 images depuis S3
- âœ… Extraction des mÃ©tadonnÃ©es (path, label, classe)
- âœ… Statistiques par classe
- âœ… Ã‰criture des rÃ©sultats sur S3

**Documentation** : [traitement/etape_1/](traitement/etape_1/)

**RÃ©sultats** :
- DurÃ©e : ~2-5 min (67,000 images)
- Output : MÃ©tadonnÃ©es + statistiques CSV
- CoÃ»t : ~0.05â‚¬

---

### Ã‰tape 2 : Feature Extraction + PCA â­

**Objectif** : Pipeline big data complet avec TensorFlow et PCA

#### Architecture du pipeline

```
Images S3 (JPG)
    â”‚
    â”œâ”€> [1] Chargement (binaryFile)
    â”‚
    â”œâ”€> [2] MobileNetV2 Feature Extraction
    â”‚       â€¢ Broadcast des poids (~14 MB)
    â”‚       â€¢ Pandas UDF (traitement distribuÃ©)
    â”‚       â€¢ Output: 1280 features par image
    â”‚
    â”œâ”€> [3] PCA (MLlib)
    â”‚       â€¢ RÃ©duction: 1280 â†’ 50 dimensions
    â”‚       â€¢ Variance conservÃ©e: 92.93%
    â”‚
    â””â”€> [4] Sauvegarde S3 (Parquet + CSV)
            â€¢ features/ (1280D)
            â€¢ pca/ (50D)
            â€¢ metadata/ (labels)
            â€¢ model_info/ (variance)
```

#### RÃ©sultats validÃ©s (Mode MINI - 300 images)

| MÃ©trique | Valeur |
|----------|--------|
| **Images traitÃ©es** | 300 (100%) |
| **Temps d'exÃ©cution** | 3min 34s |
| **DÃ©bit** | ~84 images/min |
| **Variance PCA (50 comp.)** | **92.93%** |
| **Taux d'erreur** | 0% |
| **CoÃ»t** | ~0.50â‚¬ |

#### Optimisations appliquÃ©es

- âœ… **Broadcast TensorFlow** : -90% transferts rÃ©seau
- âœ… **Pandas UDF + Arrow** : 10-100Ã— plus rapide
- âœ… **Parquet** : -50% stockage vs CSV
- âœ… **PCA 50D** : -96% dimensions (1280 â†’ 50)

#### ScalabilitÃ© estimÃ©e

| Mode | Images | DurÃ©e | CoÃ»t |
|------|--------|-------|------|
| MINI | 300 | 3min34s | 0.50â‚¬ |
| APPLES | 6,400 | ~20min | 0.40â‚¬ |
| **FULL** | **67,000** | **~2-3h** | **~1.60â‚¬** |

**Documentation complÃ¨te** : [traitement/etape_2/](traitement/etape_2/)

**Quickstart** : [traitement/etape_2/QUICKSTART.md](traitement/etape_2/QUICKSTART.md)

**RÃ©sultats dÃ©taillÃ©s** : [traitement/etape_2/docs/RESULTATS.md](traitement/etape_2/docs/RESULTATS.md)

---

## ğŸ¯ Livrables

### âœ… Code & Scripts

| Livrable | Localisation | Description |
|----------|--------------|-------------|
| **Pipeline PySpark** | [process_fruits_data.py](traitement/etape_2/scripts/process_fruits_data.py) | Script principal (MobileNetV2 + PCA) |
| **Bootstrap EMR** | [install_dependencies.sh](traitement/etape_2/scripts/install_dependencies.sh) | Installation TensorFlow, scikit-learn |
| **Scripts automatisation** | [traitement/etape_2/scripts/](traitement/etape_2/scripts/) | 11 scripts bash (create, monitor, submit, etc.) |
| **Configuration** | [config.sh](traitement/etape_2/config/config.sh) | Config centralisÃ©e (EMR, Spark, S3) |

### âœ… Documentation

| Document | Lien | Contenu |
|----------|------|---------|
| **README Ã‰tape 2** | [traitement/etape_2/docs/README.md](traitement/etape_2/docs/README.md) | Documentation complÃ¨te |
| **Quickstart** | [traitement/etape_2/QUICKSTART.md](traitement/etape_2/QUICKSTART.md) | DÃ©marrage en 7 commandes |
| **Workflow** | [traitement/etape_2/docs/WORKFLOW.md](traitement/etape_2/docs/WORKFLOW.md) | ProcÃ©dure dÃ©taillÃ©e |
| **Architecture** | [traitement/etape_2/docs/ARCHITECTURE.md](traitement/etape_2/docs/ARCHITECTURE.md) | Architecture technique |
| **RÃ©sultats** | [traitement/etape_2/docs/RESULTATS.md](traitement/etape_2/docs/RESULTATS.md) | RÃ©sultats validÃ©s |

### âœ… DonnÃ©es S3

```
s3://oc-p11-fruits-david-scanu/
â”œâ”€â”€ data/raw/Training/           # Input: ~67,000 images
â””â”€â”€ process_fruits_data/output/  # Output Ã©tape 2:
    â”œâ”€â”€ features/                # Features 1280D (5.9 MB)
    â”œâ”€â”€ pca/                     # PCA 50D (456 KB)
    â”œâ”€â”€ metadata/                # Labels (36 KB)
    â””â”€â”€ model_info/              # Variance PCA (64 KB)
```

---

## ğŸ’° CoÃ»ts AWS (rÃ©els)

| Phase | DurÃ©e | CoÃ»t |
|-------|-------|------|
| **Ã‰tape 1** (validation) | ~5 min | ~0.05â‚¬ |
| **Ã‰tape 2 (MINI)** | ~30 min | ~0.50â‚¬ |
| **Ã‰tape 2 (FULL)** | ~2-3h | ~1.60â‚¬ |
| **TOTAL projet** | - | **< 3â‚¬** |

**Auto-terminaison** : 4h idle timeout (sÃ©curitÃ© anti-coÃ»ts)

---

## âš¡ DÃ©marrage rapide

### PrÃ©requis

- AWS CLI configurÃ©
- AccÃ¨s S3 : `oc-p11-fruits-david-scanu`
- ClÃ© SSH EMR : `emr-p11-fruits-key-codespace`

### ExÃ©cution Ã‰tape 2 (7 commandes)

```bash
cd traitement/etape_2

# 1. VÃ©rifications
./scripts/verify_setup.sh

# 2. Upload scripts S3
./scripts/upload_scripts.sh

# 3. CrÃ©er cluster (~10-15 min)
./scripts/create_cluster.sh

# 4. Surveiller
./scripts/monitor_cluster.sh

# 5. Soumettre job
./scripts/submit_job.sh  # Choisir mode: mini/apples/full

# 6. TÃ©lÃ©charger rÃ©sultats
./scripts/download_results.sh

# 7. âš ï¸ ARRÃŠTER LE CLUSTER
./scripts/terminate_cluster.sh
```

**DÃ©tails** : [traitement/etape_2/QUICKSTART.md](traitement/etape_2/QUICKSTART.md)

> âš ï¸ **Gestion des coÃ»ts** : Toujours terminer le cluster aprÃ¨s usage !

## ğŸ“Š Jeu de donnÃ©es

**Fruits-360 Dataset**

- **CrÃ©ateur** : Mihai Oltean (2017-)
- **Taille** : 155,491 images rÃ©parties en 226 classes (version 100x100)
- **Format** : JPG, 100x100 pixels (standardisÃ©)
- **Contenu** : Fruits, lÃ©gumes, noix et graines avec de multiples variÃ©tÃ©s
  - 29 types de pommes
  - 12 variÃ©tÃ©s de cerises
  - 19 types de tomates
  - Et bien d'autres...
- **MÃ©thode de capture** : Images capturÃ©es par rotation (20s Ã  3 rpm) sur fond blanc
- **Licence** : CC BY-SA 4.0

**Sources** :
- [Kaggle](https://www.kaggle.com/datasets/moltean/fruits)
- [TÃ©lÃ©chargement direct](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P8/fruits.zip)


---

## ğŸ“¦ Stockage S3

### Structure des donnÃ©es

```
s3://oc-p11-fruits-david-scanu/
â”‚
â”œâ”€â”€ data/raw/Training/                 # Images source (67,000 images)
â”‚   â”œâ”€â”€ Apple Braeburn/
â”‚   â”‚   â”œâ”€â”€ 0_100.jpg
â”‚   â”‚   â”œâ”€â”€ 1_100.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Banana/
â”‚   â””â”€â”€ ... (224 classes)
â”‚
â”œâ”€â”€ read_fruits_data/                  # Outputs Ã‰tape 1
â”‚   â”œâ”€â”€ scripts/                       # Scripts uploadÃ©s
â”‚   â”œâ”€â”€ logs/emr/                      # Logs EMR
â”‚   â””â”€â”€ output/etape_1/                # MÃ©tadonnÃ©es + stats
â”‚
â””â”€â”€ process_fruits_data/               # Outputs Ã‰tape 2 â­
    â”œâ”€â”€ scripts/                       # Scripts uploadÃ©s
    â”œâ”€â”€ logs/emr/                      # Logs EMR
    â””â”€â”€ output/                        # RÃ©sultats (features, PCA, etc.)
        â”œâ”€â”€ features/
        â”œâ”€â”€ pca/
        â”œâ”€â”€ metadata/
        â””â”€â”€ model_info/
```

### Exemples de chemins

- **Image** : `s3://oc-p11-fruits-david-scanu/data/raw/Training/Apple Braeburn/0_100.jpg`
- **Features** : `s3://oc-p11-fruits-david-scanu/process_fruits_data/output/features/`
- **PCA** : `s3://oc-p11-fruits-david-scanu/process_fruits_data/output/pca/`

## Audit des coÃ»ts AWS 

Un script d'audit rapide est disponible pour lister les ressources AWS susceptibles d'engendrer des coÃ»ts (instances EC2 actives, volumes EBS, Elastic IP, buckets S3, NAT Gateway, RDS, EMR, etc.). Le script est non-destructif : il se contente de lister et rÃ©sumer les ressources.

FichierÂ : `scripts/aws_audit.sh`

- Actions effectuÃ©es : vÃ©rifications EC2 (par rÃ©gion), EBS, snapshots, AMIs privÃ©es, Elastic IPs, ELB, NAT Gateways, RDS, EKS, EFS, EMR, S3 buckets (taille via aws s3 ls --recursive --summarize), option Cost Explorer (--costs).
- Options : `--region`, `--all-regions`, -`-costs`, `--quiet`.

Usage rapide :

```bash
# rendre exÃ©cutable (une seule fois)
chmod +x scripts/aws_audit.sh

# scan rapide pour la rÃ©gion eu-west-1
./scripts/aws_audit.sh --region eu-west-1

# scan toutes les rÃ©gions (long)
./scripts/aws_audit.sh --all-regions

# inclure Cost Explorer (requiert permissions & activation)
./scripts/aws_audit.sh --region eu-west-1 --costs
```

Remarques :
- Le calcul de la taille des buckets S3 via `aws s3 ls --recursive --summarize` peut Ãªtre lent pour les gros buckets (par ex. `mlflow-artefact-store`).
- L'option `--costs` utilise l'API Cost Explorer (rÃ©gion `us-east-1`) et nÃ©cessite que le service soit activÃ© et que l'utilisateur ait la permission `ce:GetCostAndUsage`.
- Le script n'effectue aucune suppression ; les actions de nettoyage restent manuelles.

### Obtenir coÃ»ts par service sur 30 jours (Cost Explorer) :

```bash
aws ce get-cost-and-usage \
  --time-period Start=$(date -d '30 days ago' +%Y-%m-%d),End=$(date +%Y-%m-%d) \
  --granularity MONTHLY --metrics UnblendedCost \
  --group-by Type=DIMENSION,Key=SERVICE \
  --region us-east-1 \
  --query "ResultsByTime[0].Groups[].{Service: Keys[0],Amount: Metrics.UnblendedCost.Amount}" \
  --output table
```

---

## ğŸ“š Ressources & Documentation

### Documentation du projet

| Resource | Lien |
|----------|------|
| **Documentation** | [traitement/etape_2/docs/](traitement/etape_2/docs/) |
| **Quickstart** | [traitement/etape_2/QUICKSTART.md](traitement/etape_2/QUICKSTART.md) |
| **RÃ©sultats validÃ©s** | [traitement/etape_2/docs/RESULTATS.md](traitement/etape_2/docs/RESULTATS.md) |

### RÃ©fÃ©rences externes

- [AWS EMR Getting Started](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html)
- [Troubleshoot Python Libraries on EMR](https://repost.aws/fr/knowledge-center/emr-troubleshoot-python-libraries)
- [Notebook alternant (rÃ©fÃ©rence)](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P8/P8_Mode_ope%CC%81ratoire.zip)
- [Fruits-360 Dataset (Kaggle)](https://www.kaggle.com/datasets/moltean/fruits)

---

## ğŸ“… Dates

- **DÃ©but** : 24 Octobre 2025
- **Ã‰tape 1 validÃ©e** : Novembre 2025
- **Ã‰tape 2 validÃ©e** : 21 Novembre 2025

---

## ğŸ† Accomplissements

- âœ… **Pipeline PySpark** complet et scalable
- âœ… **Architecture AWS** production-ready (EMR + S3)
- âœ… **Broadcast TensorFlow** pour optimisation rÃ©seau
- âœ… **PCA MLlib** avec 92.93% de variance conservÃ©e
- âœ… **Scripts d'automatisation** (11 scripts bash)
- âœ… **Documentation exhaustive** (4 documents techniques)
- âœ… **ConformitÃ© GDPR** (rÃ©gion eu-west-1)
- âœ… **Gestion des coÃ»ts** (< 3â‚¬ total projet)

**ğŸš€ Production-ready | ğŸ“Š Big Data optimisÃ© | ğŸ” GDPR compliant**

---

## ğŸ‘¤ Auteur

> ğŸ“ OpenClassrooms â€¢ Parcours [AI Engineer](https://openclassrooms.com/fr/paths/795-ai-engineer) | ğŸ‘‹ *Ã‰tudiant* : [David Scanu](https://www.linkedin.com/in/davidscanu14/)
