# Guide de Migration AWS - Projet Big Data Fruits

**Date de cr√©ation** : 7 novembre 2025
**Objectif** : Migrer le pipeline PySpark valid√© localement vers AWS EMR

---

## Vue d'ensemble

Ce guide vous accompagne √©tape par √©tape pour :
1. Installer et configurer AWS CLI
2. Cr√©er un bucket S3 dans une r√©gion europ√©enne (RGPD)
3. Uploader le dataset sur S3
4. Cr√©er un cluster EMR avec les bonnes configurations
5. Ex√©cuter le pipeline PySpark sur EMR
6. R√©cup√©rer les r√©sultats et arr√™ter le cluster

**‚è±Ô∏è Temps estim√©** : 2-3 heures
**üí∞ Co√ªt estim√©** : 6-10‚Ç¨

---

## Pr√©requis

- ‚úÖ Compte AWS actif
- ‚úÖ Pipeline PySpark valid√© localement (`notebooks/p11-david-scanu-local-development.ipynb`)
- ‚úÖ Dataset Fruits-360 local (`data/raw/fruits-360_dataset/`)
- üî≤ AWS CLI (sera install√© dans ce guide)
- üî≤ Cl√©s d'acc√®s AWS IAM (seront g√©n√©r√©es dans ce guide)

---

## üì¶ √âtape 1 : Installation et Configuration AWS CLI

### 1.1 Installation AWS CLI v2

```bash
# T√©l√©charger AWS CLI v2 pour Linux
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"

# Extraire l'archive
unzip awscliv2.zip

# Installer (peut n√©cessiter sudo)
sudo ./aws/install

# V√©rifier l'installation
aws --version
```

**R√©sultat attendu** : `aws-cli/2.x.x Python/3.x.x Linux/x.x.x`

### 1.2 Cr√©ation des cl√©s d'acc√®s AWS IAM

**Via la console AWS** :

1. Connectez-vous √† la console AWS : https://console.aws.amazon.com
2. Naviguez vers **IAM** > **Utilisateurs** > Votre utilisateur
3. Onglet **"Informations d'identification de s√©curit√©"**
4. Cliquez sur **"Cr√©er une cl√© d'acc√®s"**
5. S√©lectionnez le cas d'utilisation : **"Interface de ligne de commande (CLI)"**
6. **IMPORTANT** : Notez la cl√© d'acc√®s et la cl√© secr√®te (elles ne seront plus affich√©es)

**Permissions requises** :
- `AmazonS3FullAccess` (pour g√©rer S3)
- `AmazonEMRFullAccess` (pour g√©rer EMR)
- `AmazonEC2FullAccess` (pour les instances EMR)

### 1.3 Configuration AWS CLI

```bash
# Configurer AWS CLI avec vos identifiants
aws configure

# Vous serez invit√© √† entrer :
# AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE
# AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# Default region name [None]: eu-west-1
# Default output format [None]: json
```

**‚ö†Ô∏è R√©gion importante** : Utilisez **`eu-west-1`** (Irlande) ou **`eu-central-1`** (Francfort) pour la conformit√© RGPD.

### 1.4 V√©rification de la configuration

```bash
# V√©rifier l'identit√© AWS
aws sts get-caller-identity

# V√©rifier l'acc√®s S3
aws s3 ls
```

**R√©sultat attendu** : Affichage de votre ID utilisateur et compte AWS

---

## ü™£ √âtape 2 : Cr√©ation du Bucket S3

### 2.1 Cr√©er le bucket S3

```bash
# D√©finir les variables
BUCKET_NAME="oc-p11-fruits-$(date +%Y%m%d)"
REGION="eu-west-1"

# Cr√©er le bucket
aws s3 mb s3://${BUCKET_NAME} --region ${REGION}

# V√©rifier la cr√©ation
aws s3 ls
```

**‚ö†Ô∏è Note** : Le nom du bucket doit √™tre unique globalement. Si le nom est d√©j√† pris, modifiez-le.

### 2.2 Configurer le bucket pour RGPD

```bash
# Bloquer l'acc√®s public (bonne pratique)
aws s3api put-public-access-block \
    --bucket ${BUCKET_NAME} \
    --public-access-block-configuration \
    "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"

# V√©rifier la configuration
aws s3api get-bucket-location --bucket ${BUCKET_NAME}
```

**R√©sultat attendu** : `"LocationConstraint": "eu-west-1"`

### 2.3 Cr√©er la structure de dossiers S3

```bash
# Cr√©er les dossiers (en cr√©ant des fichiers placeholder)
aws s3api put-object --bucket ${BUCKET_NAME} --key data/raw/
aws s3api put-object --bucket ${BUCKET_NAME} --key data/features/
aws s3api put-object --bucket ${BUCKET_NAME} --key data/pca/
aws s3api put-object --bucket ${BUCKET_NAME} --key logs/

# V√©rifier la structure
aws s3 ls s3://${BUCKET_NAME}/ --recursive
```

---

## üì§ √âtape 3 : Upload du Dataset sur S3

### 3.1 Upload du dataset Training

**‚ö†Ô∏è Important** : L'upload de ~1.5 GB peut prendre 10-30 minutes selon votre connexion.

```bash
# Se placer √† la racine du projet
cd /home/david/projects/openclassrooms/projets/oc-ai-engineer-p11-realisez-traitement-environnement-big-data-cloud

# Upload du dataset Training (avec barre de progression)
aws s3 sync data/raw/fruits-360_dataset/fruits-360/Training/ \
    s3://${BUCKET_NAME}/data/raw/Training/ \
    --region ${REGION} \
    --exclude "*.DS_Store"

# V√©rifier l'upload
aws s3 ls s3://${BUCKET_NAME}/data/raw/Training/ | head -20
```

### 3.2 V√©rifier le nombre d'images upload√©es

```bash
# Compter les fichiers upload√©s
aws s3 ls s3://${BUCKET_NAME}/data/raw/Training/ --recursive | wc -l

# Devrait afficher environ 67,692 lignes (+ dossiers)
```

### 3.3 Upload du dataset Test (optionnel)

```bash
# Upload du dataset Test (si n√©cessaire pour tests)
aws s3 sync data/raw/fruits-360_dataset/fruits-360/Test/ \
    s3://${BUCKET_NAME}/data/raw/Test/ \
    --region ${REGION} \
    --exclude "*.DS_Store"
```

### 3.4 V√©rifier la taille totale sur S3

```bash
# Afficher la taille du bucket
aws s3 ls s3://${BUCKET_NAME}/data/raw/ --recursive --human-readable --summarize
```

**R√©sultat attendu** : `Total Size: ~1.5 GB`

---

## üñ•Ô∏è √âtape 4 : Cr√©ation du Cluster EMR

### 4.1 Cr√©er une paire de cl√©s SSH

```bash
# Cr√©er une paire de cl√©s pour SSH
KEY_NAME="emr-p11-fruits-key"

aws ec2 create-key-pair \
    --key-name ${KEY_NAME} \
    --query 'KeyMaterial' \
    --output text \
    --region ${REGION} > ~/.ssh/${KEY_NAME}.pem

# S√©curiser la cl√©
chmod 400 ~/.ssh/${KEY_NAME}.pem

# V√©rifier
ls -l ~/.ssh/${KEY_NAME}.pem
```

### 4.2 Cr√©er le cluster EMR

**‚ö†Ô∏è ATTENTION : Cette commande va lancer un cluster qui co√ªte ~2-3‚Ç¨/heure**

```bash
# D√©finir les variables du cluster
CLUSTER_NAME="P11-Fruits-BigData-$(date +%Y%m%d)"
EMR_RELEASE="emr-7.5.0"  # Version stable avec Spark 3.5.x et TensorFlow 2.16.x
INSTANCE_TYPE="m5.xlarge"

# Cr√©er le cluster
CLUSTER_ID=$(aws emr create-cluster \
    --name "${CLUSTER_NAME}" \
    --region ${REGION} \
    --release-label ${EMR_RELEASE} \
    --applications Name=Spark Name=JupyterHub Name=Hadoop Name=TensorFlow \
    --instance-groups \
        InstanceGroupType=MASTER,InstanceCount=1,InstanceType=${INSTANCE_TYPE} \
        InstanceGroupType=CORE,InstanceCount=2,InstanceType=${INSTANCE_TYPE} \
    --ec2-attributes KeyName=${KEY_NAME} \
    --use-default-roles \
    --log-uri s3://${BUCKET_NAME}/logs/ \
    --enable-debugging \
    --configurations '[
        {
            "Classification": "spark",
            "Properties": {
                "maximizeResourceAllocation": "true"
            }
        }
    ]' \
    --query 'ClusterId' \
    --output text)

echo "Cluster cr√©√© avec l'ID: ${CLUSTER_ID}"
echo "Sauvegarde de l'ID dans un fichier..."
echo ${CLUSTER_ID} > cluster_id.txt
```

**üìù Note** : Le cluster met environ 10-15 minutes √† d√©marrer.

### 4.3 Suivre le statut du cluster

```bash
# Afficher le statut du cluster
aws emr describe-cluster --cluster-id ${CLUSTER_ID} --query 'Cluster.Status.State'

# Suivre les logs en temps r√©el (√† r√©p√©ter toutes les 30 secondes)
watch -n 30 "aws emr describe-cluster --cluster-id ${CLUSTER_ID} --query 'Cluster.Status.State'"

# Attendre que le statut soit "WAITING"
```

**√âtats possibles** :
- `STARTING` : Cluster en cours de d√©marrage
- `BOOTSTRAPPING` : Installation des applications
- `RUNNING` : Cluster en cours d'ex√©cution
- `WAITING` : ‚úÖ **Pr√™t √† recevoir des jobs**
- `TERMINATING` : Cluster en cours d'arr√™t
- `TERMINATED` : Cluster arr√™t√©

### 4.4 R√©cup√©rer l'adresse du Master Node

```bash
# Une fois le cluster en √©tat WAITING, r√©cup√©rer l'IP publique du master
MASTER_DNS=$(aws emr describe-cluster \
    --cluster-id ${CLUSTER_ID} \
    --query 'Cluster.MasterPublicDnsName' \
    --output text)

echo "Master DNS: ${MASTER_DNS}"
echo ${MASTER_DNS} > master_dns.txt
```

---

## üîê √âtape 5 : Connexion SSH et Tunnel

### 5.1 Configurer le tunnel SSH vers JupyterHub

```bash
# Cr√©er le tunnel SSH (port 9443 pour JupyterHub sur EMR 7.x)
ssh -i ~/.ssh/${KEY_NAME}.pem \
    -N -L 9443:${MASTER_DNS}:9443 \
    hadoop@${MASTER_DNS}
```

**‚ö†Ô∏è Cette commande ne retourne pas** : Le tunnel reste actif. Laissez ce terminal ouvert.

**En cas d'erreur de permission** :
```bash
# Ouvrir le security group pour SSH
SECURITY_GROUP=$(aws emr describe-cluster \
    --cluster-id ${CLUSTER_ID} \
    --query 'Cluster.Ec2InstanceAttributes.EmrManagedMasterSecurityGroup' \
    --output text)

aws ec2 authorize-security-group-ingress \
    --group-id ${SECURITY_GROUP} \
    --protocol tcp \
    --port 22 \
    --cidr $(curl -s https://checkip.amazonaws.com)/32
```

### 5.2 Acc√©der √† JupyterHub

1. **Ouvrir un navigateur** : https://localhost:9443
2. **Accepter le certificat SSL** (auto-sign√©, c'est normal)
3. **Se connecter avec** :
   - Username : `jovyan`
   - Password : `jupyter`

**Alternative - Via la console AWS** :
- Console AWS > EMR > Clusters > Votre cluster
- Onglet "Application User Interfaces"
- Cliquer sur "JupyterHub"

---

## üìì √âtape 6 : Cr√©ation et Ex√©cution du Notebook sur EMR

### 6.1 Cr√©er un nouveau notebook PySpark

Dans JupyterHub :
1. Cliquer sur **"New"** > **"PySpark"**
2. Renommer le notebook : `P11_David_Scanu_Production_EMR.ipynb`

### 6.2 Adapter le code local pour EMR

**Principales modifications** :

#### A) Pas besoin de cr√©er la SparkSession

```python
# ‚ùå LOCAL - Ne PAS utiliser sur EMR
# spark = SparkSession.builder.appName("...").master("local[*]").getOrCreate()

# ‚úÖ EMR - La SparkSession existe d√©j√†
# V√©rifier simplement qu'elle existe
print(f"Spark version: {spark.version}")
print(f"SparkContext: {spark.sparkContext.master}")
sc = spark.sparkContext
```

#### B) Modifier les chemins pour S3

```python
# ‚ùå LOCAL
# image_path = "file:///path/to/Training/Apple*/*.jpg"

# ‚úÖ EMR - Utiliser S3
BUCKET_NAME = "oc-p11-fruits-20251107"  # Remplacer par votre bucket
image_path = f"s3://{BUCKET_NAME}/data/raw/Training/Apple*/*.jpg"

# Pour le dataset complet
# image_path = f"s3://{BUCKET_NAME}/data/raw/Training/*/*.jpg"
```

#### C) Installer TensorFlow et Pillow (si n√©cessaire)

```python
# Installer les d√©pendances dans le notebook
import sys
import subprocess

def install_package(package):
    subprocess.check_call([sys.executable, "-m", "pip", "install", package])

# Installer TensorFlow et Pillow
install_package("tensorflow==2.16.1")
install_package("pillow")

print("‚úÖ Packages install√©s")
```

#### D) Adapter les chemins de sauvegarde

```python
# ‚ùå LOCAL
# features_output = "/local/path/features"

# ‚úÖ EMR - Sauvegarder sur S3
features_output = f"s3://{BUCKET_NAME}/data/features/mobilenetv2_features"
pca_output = f"s3://{BUCKET_NAME}/data/pca/pca_results"
```

### 6.3 Copier le code du notebook local

**Option A - Copier-coller** :
1. Ouvrir le notebook local : `notebooks/p11-david-scanu-local-development.ipynb`
2. Copier le code cellule par cellule dans le notebook EMR
3. Appliquer les modifications ci-dessus

**Option B - Upload direct** (recommand√©) :
```bash
# Depuis votre machine locale, uploader le notebook vers S3
aws s3 cp notebooks/p11-david-scanu-local-development.ipynb \
    s3://${BUCKET_NAME}/notebooks/

# Puis le t√©l√©charger depuis JupyterHub via l'interface web
```

### 6.4 Ex√©cuter le pipeline complet

**üéØ Strat√©gie d'ex√©cution recommand√©e** :

#### Phase 1 : Test rapide (100 images)
```python
# Tester d'abord avec un petit subset
TEST_MODE = "mini"
MAX_IMAGES = 100
image_path = f"s3://{BUCKET_NAME}/data/raw/Training/Apple*/*.jpg"
df_images = spark.read.format("binaryFile").load(image_path).limit(MAX_IMAGES)
```

**Temps estim√©** : 5-10 minutes

#### Phase 2 : Dataset complet (67,692 images)
```python
# Une fois le test valid√©, lancer le dataset complet
TEST_MODE = "full"
image_path = f"s3://{BUCKET_NAME}/data/raw/Training/*/*.jpg"
df_images = spark.read.format("binaryFile").load(image_path)
```

**Temps estim√©** : 2-4 heures (selon la configuration du cluster)

### 6.5 Monitorer l'ex√©cution via Spark UI

**Acc√©der √† Spark UI** :

1. **Via le tunnel SSH** (recommand√©) :
```bash
# Dans un nouveau terminal, cr√©er un tunnel pour Spark UI
ssh -i ~/.ssh/${KEY_NAME}.pem \
    -N -L 18080:${MASTER_DNS}:18080 \
    hadoop@${MASTER_DNS}
```
Puis ouvrir : http://localhost:18080

2. **Via la console AWS** :
   - Console AWS > EMR > Clusters > Votre cluster
   - Onglet "Application User Interfaces"
   - Cliquer sur "Spark History Server"

**M√©triques √† surveiller** :
- Nombre de t√¢ches en cours
- Temps d'ex√©cution des stages
- Utilisation m√©moire
- Erreurs √©ventuelles

---

## üì• √âtape 7 : R√©cup√©ration des R√©sultats

### 7.1 V√©rifier les r√©sultats sur S3

```bash
# Lister les fichiers de features
aws s3 ls s3://${BUCKET_NAME}/data/features/ --recursive --human-readable

# Lister les fichiers PCA
aws s3 ls s3://${BUCKET_NAME}/data/pca/ --recursive --human-readable

# Afficher la taille totale
aws s3 ls s3://${BUCKET_NAME}/data/ --recursive --human-readable --summarize
```

### 7.2 T√©l√©charger les r√©sultats localement

```bash
# T√©l√©charger les features
aws s3 sync s3://${BUCKET_NAME}/data/features/ \
    data/emr_output/features/ \
    --region ${REGION}

# T√©l√©charger les r√©sultats PCA
aws s3 sync s3://${BUCKET_NAME}/data/pca/ \
    data/emr_output/pca/ \
    --region ${REGION}

# V√©rifier
ls -lh data/emr_output/
```

### 7.3 Inspecter les r√©sultats PCA (optionnel)

```python
# Dans un notebook local ou JupyterHub
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Inspect-Results").getOrCreate()

# Charger les r√©sultats PCA depuis S3
df_pca = spark.read.parquet(f"s3://{BUCKET_NAME}/data/pca/pca_results")

# Afficher les statistiques
print(f"Nombre de lignes: {df_pca.count()}")
df_pca.printSchema()
df_pca.show(10, truncate=60)
```

---

## üõë √âtape 8 : Arr√™t du Cluster EMR

**‚ö†Ô∏è CRITIQUE : NE PAS OUBLIER D'ARR√äTER LE CLUSTER**

### 8.1 V√©rifier que les donn√©es sont bien sur S3

```bash
# V√©rifier une derni√®re fois
aws s3 ls s3://${BUCKET_NAME}/data/pca/ --recursive
```

### 8.2 Arr√™ter le cluster

```bash
# Arr√™ter le cluster
aws emr terminate-clusters --cluster-ids ${CLUSTER_ID}

# V√©rifier le statut
aws emr describe-cluster --cluster-id ${CLUSTER_ID} --query 'Cluster.Status.State'
```

**√âtat attendu** : `TERMINATING` puis `TERMINATED`

### 8.3 V√©rifier l'arr√™t dans la console AWS

1. Console AWS > EMR > Clusters
2. V√©rifier que le cluster est en √©tat **"Terminated"**
3. ‚úÖ Plus de facturation

---

## üí∞ √âtape 9 : Gestion des Co√ªts

### 9.1 V√©rifier les co√ªts

**Console AWS** :
1. AWS Console > Billing > Bills
2. Filtrer par service : EMR, S3, EC2
3. V√©rifier les co√ªts du mois en cours

### 9.2 Estimation des co√ªts

| Service | Ressource | Dur√©e | Co√ªt unitaire | Total |
|---------|-----------|-------|---------------|-------|
| EMR | 1 master m5.xlarge | 3h | 0.23‚Ç¨/h | ~0.70‚Ç¨ |
| EMR | 2 core m5.xlarge | 3h | 0.23‚Ç¨/h √ó 2 | ~1.40‚Ç¨ |
| EMR | EMR surcharge | 3h | 0.07‚Ç¨/h √ó 3 | ~0.20‚Ç¨ |
| S3 | Stockage 2 GB | 1 mois | 0.023‚Ç¨/GB | ~0.05‚Ç¨ |
| S3 | Transfert 1.5 GB upload | - | Gratuit | 0‚Ç¨ |
| **TOTAL** | | | | **~2.35‚Ç¨** |

**‚ö†Ô∏è Note** : Si le dataset complet prend 4h √† traiter, pr√©voir ~3-4‚Ç¨

### 9.3 Nettoyage S3 (apr√®s projet)

**Supprimer le bucket S3** (apr√®s validation du projet) :

```bash
# Supprimer tous les fichiers du bucket
aws s3 rm s3://${BUCKET_NAME}/ --recursive

# Supprimer le bucket
aws s3 rb s3://${BUCKET_NAME}

# V√©rifier
aws s3 ls
```

---

## üìã Checklist Compl√®te

### Avant de commencer
- [ ] Compte AWS actif
- [ ] Carte de cr√©dit configur√©e sur AWS
- [ ] Pipeline local valid√©
- [ ] Dataset local disponible

### Installation et configuration (30 min)
- [ ] AWS CLI install√©
- [ ] Cl√©s IAM cr√©√©es
- [ ] AWS CLI configur√© avec r√©gion EU
- [ ] Identit√© AWS v√©rifi√©e

### Bucket S3 (30 min)
- [ ] Bucket S3 cr√©√© en r√©gion EU
- [ ] Acc√®s public bloqu√©
- [ ] Structure de dossiers cr√©√©e
- [ ] Dataset upload√© (67,692 images)
- [ ] Upload v√©rifi√©

### Cluster EMR (15 min cr√©ation + 3h ex√©cution)
- [ ] Paire de cl√©s SSH cr√©√©e
- [ ] Cluster EMR lanc√©
- [ ] Cluster en √©tat WAITING
- [ ] DNS du master r√©cup√©r√©

### Ex√©cution (3-4h)
- [ ] Tunnel SSH cr√©√©
- [ ] JupyterHub accessible
- [ ] Notebook cr√©√© sur EMR
- [ ] Code adapt√© pour S3
- [ ] Test sur 100 images r√©ussi
- [ ] Dataset complet trait√©
- [ ] R√©sultats v√©rifi√©s sur S3

### R√©sultats et nettoyage (30 min)
- [ ] Features t√©l√©charg√©es
- [ ] R√©sultats PCA t√©l√©charg√©s
- [ ] Cluster EMR arr√™t√© (TERMINATED)
- [ ] Co√ªts v√©rifi√©s

### Apr√®s le projet
- [ ] Bucket S3 supprim√© (optionnel)
- [ ] Cl√©s IAM d√©sactiv√©es (si non r√©utilis√©es)

---

## üö® D√©pannage

### Probl√®me : AWS CLI non trouv√© apr√®s installation

```bash
# V√©rifier le PATH
echo $PATH

# Ajouter au PATH si n√©cessaire
export PATH=$PATH:/usr/local/bin

# Ou relancer le terminal
```

### Probl√®me : Connexion SSH refus√©e

```bash
# V√©rifier que le security group autorise votre IP
MY_IP=$(curl -s https://checkip.amazonaws.com)
echo "Votre IP publique: ${MY_IP}"

# Ouvrir le port SSH pour votre IP
aws ec2 authorize-security-group-ingress \
    --group-id ${SECURITY_GROUP} \
    --protocol tcp \
    --port 22 \
    --cidr ${MY_IP}/32
```

### Probl√®me : Import TensorFlow √©choue sur EMR

```python
# Installer TensorFlow dans une cellule du notebook
import sys
!{sys.executable} -m pip install tensorflow==2.16.1

# Red√©marrer le kernel apr√®s installation
```

### Probl√®me : Out of Memory sur EMR

```python
# R√©duire le nombre d'images trait√©es en parall√®le
spark.conf.set("spark.sql.execution.arrow.maxRecordsPerBatch", "512")

# Ou augmenter la m√©moire des executors via la configuration du cluster
```

### Probl√®me : Cluster bloqu√© en √©tat STARTING

```bash
# V√©rifier les logs du cluster
aws emr describe-cluster --cluster-id ${CLUSTER_ID}

# Si bloqu√© > 20 min, arr√™ter et recr√©er
aws emr terminate-clusters --cluster-ids ${CLUSTER_ID}
```

---

## üìö Ressources Compl√©mentaires

**Documentation AWS** :
- [AWS CLI Installation](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
- [EMR Getting Started](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html)
- [EMR avec JupyterHub](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-jupyterhub.html)
- [S3 Best Practices](https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html)

**Pricing** :
- [EMR Pricing Calculator](https://aws.amazon.com/emr/pricing/)
- [S3 Pricing](https://aws.amazon.com/s3/pricing/)

**Support** :
- [AWS Forums](https://forums.aws.amazon.com/)
- [Stack Overflow - aws-emr](https://stackoverflow.com/questions/tagged/amazon-emr)

---

## üéØ Prochaines √âtapes

Apr√®s avoir termin√© la migration AWS :

1. **Documentation** :
   - Finaliser le notebook avec commentaires
   - Exporter le notebook en HTML
   - Documenter les r√©sultats et performances

2. **Pr√©sentation** :
   - Cr√©er le support de pr√©sentation
   - Pr√©parer les sch√©mas d'architecture
   - Screenshots du code cl√© et de l'ex√©cution EMR

3. **Livrables finaux** :
   - `David_Scanu_1_notebook_112025.ipynb`
   - `David_Scanu_2_images_112025.pdf` (lien S3 + screenshots)
   - `David_Scanu_3_presentation_112025.pdf`

---

**Derni√®re mise √† jour** : 7 Novembre 2025
**Auteur** : Guide cr√©√© pour le Projet 11 OpenClassrooms