# Guide Complet : Migration vers AWS EMR Studio

**Projet** : OpenClassrooms P11 - Big Data Fruits
**Date** : 2025-11-14
**Objectif** : Migrer de JupyterHub (cluster EMR) vers EMR Studio

---

## üìã Table des Mati√®res

1. [Diff√©rences JupyterHub vs EMR Studio](#diff√©rences-jupyterhub-vs-emr-studio)
2. [Pr√©requis](#pr√©requis)
3. [Installation √âtape par √âtape](#installation-√©tape-par-√©tape)
4. [Utilisation du Notebook](#utilisation-du-notebook)
5. [Optimisations et Bonnes Pratiques](#optimisations-et-bonnes-pratiques)
6. [D√©pannage](#d√©pannage)
7. [Co√ªts et Gestion](#co√ªts-et-gestion)

---

## üîÑ Diff√©rences JupyterHub vs EMR Studio

### Architecture

| Aspect | JupyterHub (ancien) | EMR Studio (nouveau) |
|--------|---------------------|----------------------|
| **Interface** | JupyterHub install√© sur master node | Interface web AWS manag√©e |
| **Connexion** | Tunnel SSH (port 9443) | Acc√®s web direct (SSO/IAM) |
| **Kernel** | Install√© sur cluster | G√©r√© par Livy (remote) |
| **SparkSession** | Cr√©√©e manuellement | Auto-cr√©√©e via Livy |
| **Applications EMR** | JupyterHub + Spark + Hadoop | Livy + Spark |
| **Persistance** | Locale sur cluster | S3 (auto-sauvegarde) |
| **Collaboration** | Non | Oui (workspaces partag√©s) |
| **Gestion** | Manuelle | Manag√©e par AWS |

### Avantages d'EMR Studio

‚úÖ **Pas de tunnel SSH** : Acc√®s direct via console AWS
‚úÖ **Auto-sauvegarde S3** : Notebooks sauvegard√©s automatiquement
‚úÖ **Multi-clusters** : Attacher diff√©rents clusters √† un workspace
‚úÖ **Collaboration** : Partage de workspaces entre √©quipes
‚úÖ **S√©curit√© IAM** : Gestion fine des permissions
‚úÖ **Git int√©gr√©** : Connexion directe √† GitHub/GitLab
‚úÖ **Debugging** : Meilleur suivi des jobs Spark

### Inconv√©nients

‚ö†Ô∏è **Setup initial plus complexe** : N√©cessite VPC, IAM roles, security groups
‚ö†Ô∏è **Latence** : Communication via Livy (l√©g√®rement plus lent)
‚ö†Ô∏è **D√©pendances** : Infrastructure AWS obligatoire (VPC, subnets)

---

## üì¶ Pr√©requis

### 1. AWS CLI v2

```bash
# V√©rifier l'installation
aws --version

# Si non install√©
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install
```

### 2. Configuration AWS

```bash
# Configurer les credentials
aws configure

# V√©rifier
aws sts get-caller-identity
```

**IMPORTANT** : Utiliser une r√©gion europ√©enne (RGPD) :
- `eu-west-1` (Irlande) - **recommand√©**
- `eu-west-3` (Paris)
- `eu-central-1` (Francfort)

### 3. Dataset Fruits-360

```bash
# T√©l√©charger le dataset (si non pr√©sent)
mkdir -p data/raw
cd data/raw
wget https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P8/fruits.zip
unzip fruits.zip
```

---

## üöÄ Installation √âtape par √âtape

### √âtape 1 : Cr√©er le bucket S3

```bash
./scripts/aws_emr_studio_setup.sh create-bucket
```

**Ce qui se passe** :
- Cr√©ation d'un bucket S3 avec nom unique
- Configuration du blocage d'acc√®s public
- Cr√©ation de la structure de dossiers :
  - `data/raw/` - Donn√©es brutes
  - `data/features/` - Features extraites
  - `data/pca/` - R√©sultats PCA
  - `logs/` - Logs EMR
  - `emr-studio-workspaces/` - Notebooks

**R√©sultat** :
```
‚úÖ Bucket cr√©√©: s3://oc-p11-fruits-YYYYMMDD-HHMMSS
Configuration sauvegard√©e dans .aws/emr_studio_config.env
```

### √âtape 2 : Uploader le dataset

```bash
./scripts/aws_emr_studio_setup.sh upload-dataset
```

**Dur√©e** : 10-30 minutes selon connexion internet
**Taille** : ~1.5 GB (67,692 images)

### √âtape 3 : Cr√©er les r√¥les IAM

```bash
./scripts/aws_emr_studio_setup.sh create-iam-roles
```

**R√¥les cr√©√©s** :
1. **EMRStudio_Service_Role** : Utilis√© par EMR Studio pour g√©rer les clusters
2. **EMRStudio_User_Role** : Permissions pour les utilisateurs

### √âtape 4 : Cr√©er EMR Studio

```bash
./scripts/aws_emr_studio_setup.sh create-studio
```

**Ce qui se passe** :
- D√©tection automatique du VPC par d√©faut
- Cr√©ation des security groups
- Cr√©ation du studio EMR
- R√©cup√©ration de l'URL d'acc√®s

**R√©sultat** :
```
‚úÖ EMR Studio cr√©√©: es-XXXXXXXXXXXXX
‚úÖ URL: https://XXXXX.emrstudio-prod.eu-west-1.amazonaws.com
```

### √âtape 5 : Cr√©er le cluster EMR

```bash
./scripts/aws_emr_studio_setup.sh create-cluster m5.xlarge
```

**Configuration** :
- Release : `emr-7.5.0`
- Applications : Spark + Livy (pas JupyterHub !)
- Instances : 1 master + 2 core
- Type : `m5.xlarge` (par d√©faut)

**Co√ªt estim√©** : ~2-3‚Ç¨/heure

**Dur√©e de d√©marrage** : 10-15 minutes

### √âtape 6 : V√©rifier le statut

```bash
./scripts/aws_emr_studio_setup.sh status
```

**Attendez l'√©tat** : `WAITING` (pr√™t)

---

## üíª Utilisation du Notebook

### 1. Acc√©der √† EMR Studio

1. Ouvrir l'URL du studio (affich√©e lors de la cr√©ation)
2. Se connecter avec IAM
3. Cliquer sur **"Create Workspace"**

**Configuration du workspace** :
- Name : `P11-Fruits-Workspace`
- Cluster : S√©lectionner le cluster cr√©√©
- S3 location : Auto-configur√©

### 2. Uploader le notebook

1. Dans le workspace, cliquer sur **"Upload"**
2. S√©lectionner : `notebooks/p11-emr-studio-fruits-pca.ipynb`
3. Ouvrir le notebook

### 3. Configurer le bucket

**Modifier la cellule 1.5** :

```python
# ‚ö†Ô∏è ADAPTER LE NOM DU BUCKET
BUCKET_NAME = "oc-p11-fruits-VOTRE-BUCKET"
```

Remplacer par le nom de votre bucket (affich√© lors de la cr√©ation).

### 4. Ex√©cuter le pipeline

**Recommandation** : Commencer en mode `mini` (100 images)

```python
# MODE 1: MINI TEST (100 images) - RECOMMAND√â pour d√©buter
TEST_MODE = "mini"
MAX_IMAGES = 100
```

**Ex√©cution** :
1. Ex√©cuter les cellules s√©quentiellement
2. V√©rifier les logs Spark
3. Surveiller les m√©triques (CPU, m√©moire)

### 5. Modes de production

Une fois le test r√©ussi, passer au mode production :

```python
# MODE 3: DATASET COMPLET (~67,000 images)
TEST_MODE = "full"
```

**Dur√©e estim√©e** (full dataset) :
- Chargement : 2-5 min
- Feature extraction : 30-60 min (d√©pend du cluster)
- PCA : 5-10 min
- Sauvegarde : 2-5 min

**Total** : ~45-80 minutes

---

## ‚ö° Optimisations et Bonnes Pratiques

### 1. Broadcast des poids TensorFlow

**‚úÖ Impl√©ment√© dans le notebook** :

```python
# Broadcaster les poids √† tous les workers
broadcast_weights = sc.broadcast(model_weights)
```

**Impact** :
- Sans broadcast : ~10 MB √ó nombre de workers √ó nombre de partitions
- Avec broadcast : ~10 MB √ó 1 (une seule fois)

### 2. Cache des DataFrames

```python
df_features.cache()
df_for_pca.cache()
```

**Lib√©rer la m√©moire apr√®s usage** :

```python
df_features.unpersist()
```

### 3. Configuration Spark optimale

D√©j√† configur√©e dans le script de cr√©ation du cluster :

```json
{
  "Classification": "spark",
  "Properties": {
    "maximizeResourceAllocation": "true"
  }
}
```

### 4. Partitionnement

Pour le dataset complet, augmenter le nombre de partitions :

```python
df_images = spark.read.format("binaryFile") \
    .load(image_path) \
    .repartition(200)  # Adapter selon le cluster
```

### 5. Gestion de la session Livy

Augmenter le timeout si n√©cessaire (d√©j√† configur√© √† 2h) :

```json
{
  "Classification": "livy-conf",
  "Properties": {
    "livy.server.session.timeout": "2h"
  }
}
```

---

## üîß D√©pannage

### Probl√®me : Session Livy timeout

**Sympt√¥me** : `Session ... has been idle for more than ...`

**Solution** :
```python
# Ajouter des actions interm√©diaires pour garder la session active
df.count()  # Action Spark
```

### Probl√®me : TensorFlow non trouv√© dans les workers

**Sympt√¥me** : `ModuleNotFoundError: No module named 'tensorflow'`

**Solution** :
```python
# R√©installer sur tous les workers
sc.install_pypi_package("tensorflow==2.16.1", reinstall=True)
```

### Probl√®me : M√©moire insuffisante

**Sympt√¥me** : `OutOfMemoryError` ou jobs qui √©chouent

**Solutions** :
1. R√©duire la taille des batches dans Pandas UDF
2. Augmenter le type d'instance (ex: `m5.2xlarge`)
3. Augmenter le nombre de workers

### Probl√®me : Broadcast trop gros

**Sympt√¥me** : `Broadcast size exceeds ...`

**Solution** : Utiliser un mod√®le plus l√©ger (ex: MobileNetV3-Small)

### Probl√®me : Cluster non accessible

**Sympt√¥me** : Cannot attach cluster

**Solution** :
```bash
# V√©rifier l'√©tat
./scripts/aws_emr_studio_setup.sh status

# Attendre l'√©tat WAITING
```

---

## üí∞ Co√ªts et Gestion

### Estimation des co√ªts

**Cluster 3 instances m5.xlarge (eu-west-1)** :
- Prix EMR : ~0.27‚Ç¨/h par instance
- Prix EC2 : ~0.23‚Ç¨/h par instance
- **Total** : ~1.50‚Ç¨/h (3 instances)

**Sc√©narios** :

| Dur√©e | Co√ªt estim√© |
|-------|-------------|
| 1 heure (test) | 1.50‚Ç¨ |
| 2 heures (full dataset) | 3.00‚Ç¨ |
| Journ√©e compl√®te (8h) | 12.00‚Ç¨ |
| Oubli 1 semaine | ~250‚Ç¨ ‚ö†Ô∏è |

### üö® IMPORTANT : Arr√™ter le cluster

**Toujours arr√™ter le cluster apr√®s utilisation** :

```bash
./scripts/aws_emr_studio_setup.sh terminate
```

### V√©rification finale

```bash
# V√©rifier qu'aucun cluster ne tourne
aws emr list-clusters --active

# V√©rifier les buckets S3 (les buckets co√ªtent peu)
aws s3 ls
```

### T√©l√©charger les r√©sultats avant arr√™t

```bash
./scripts/aws_emr_studio_setup.sh download-results
```

**R√©sultats locaux** :
- `data/emr_output/features/` - Features extraites
- `data/emr_output/pca/` - R√©sultats PCA

### Nettoyage complet (fin de projet)

```bash
./scripts/aws_emr_studio_setup.sh cleanup
```

**‚ö†Ô∏è ATTENTION** : Supprime TOUT (cluster + studio + S3 + IAM roles)

---

## üìä Comparaison des Approches

### JupyterHub (ancienne m√©thode)

**Workflow** :
1. Cr√©er cluster avec `JupyterHub` application
2. Tunnel SSH vers port 9443
3. Connexion avec credentials
4. Notebook local sur master node

**Commandes** :
```bash
# Ancien script
./scripts/aws_setup.sh create-cluster
./scripts/aws_setup.sh connect  # Tunnel SSH
# Naviguer vers https://localhost:9443
```

### EMR Studio (nouvelle m√©thode)

**Workflow** :
1. Cr√©er EMR Studio (une seule fois)
2. Cr√©er cluster avec `Livy` application
3. Cr√©er workspace dans EMR Studio
4. Attacher cluster au workspace
5. Uploader et ex√©cuter notebook

**Commandes** :
```bash
# Nouveau script
./scripts/aws_emr_studio_setup.sh create-studio
./scripts/aws_emr_studio_setup.sh create-cluster
# Ouvrir EMR Studio URL dans navigateur
```

---

## üéØ Checklist de Migration

### Avant de commencer

- [ ] AWS CLI v2 install√© et configur√©
- [ ] R√©gion europ√©enne s√©lectionn√©e (RGPD)
- [ ] Dataset Fruits-360 t√©l√©charg√© localement
- [ ] Budget AWS confirm√© (~10‚Ç¨)

### Configuration initiale

- [ ] Bucket S3 cr√©√©
- [ ] Dataset upload√© sur S3
- [ ] R√¥les IAM cr√©√©s
- [ ] EMR Studio cr√©√©
- [ ] URL du studio sauvegard√©e

### Ex√©cution

- [ ] Cluster EMR cr√©√© avec Livy
- [ ] Cluster en √©tat WAITING
- [ ] Workspace cr√©√© dans EMR Studio
- [ ] Cluster attach√© au workspace
- [ ] Notebook upload√©
- [ ] Bucket name configur√© dans le notebook
- [ ] Test mode `mini` ex√©cut√© avec succ√®s
- [ ] Mode `full` ex√©cut√© (optionnel)

### Finalisation

- [ ] R√©sultats v√©rifi√©s sur S3
- [ ] R√©sultats t√©l√©charg√©s localement
- [ ] Cluster EMR arr√™t√© ‚úÖ
- [ ] Co√ªts v√©rifi√©s dans AWS Cost Explorer

---

## üìö Ressources

### Documentation AWS

- [EMR Studio User Guide](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio.html)
- [EMR Cluster Configuration](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan.html)
- [Livy REST API](https://livy.incubator.apache.org/docs/latest/rest-api.html)

### Scripts du projet

- `scripts/aws_emr_studio_setup.sh` - Setup EMR Studio
- `scripts/aws_setup.sh` - Setup JupyterHub (ancien, pour r√©f√©rence)
- `notebooks/p11-emr-studio-fruits-pca.ipynb` - Notebook EMR Studio
- `notebooks/p11-emr-fruits-pca.ipynb` - Notebook JupyterHub (ancien)

### Support

En cas de probl√®me :
1. V√©rifier les logs dans AWS EMR Console
2. Consulter cette documentation
3. V√©rifier les security groups et IAM roles

---

## ‚ú® Conclusion

EMR Studio offre une exp√©rience plus moderne et professionnelle pour le d√©veloppement PySpark, au prix d'une complexit√© initiale plus √©lev√©e. Une fois configur√©, l'environnement est plus stable, s√©curis√© et collaboratif que JupyterHub.

**Recommandation** : Utiliser EMR Studio pour les projets professionnels et collaboratifs, JupyterHub reste acceptable pour les prototypes rapides et tests individuels.