################################################################################
# COMMANDES AWS - Aide-mémoire pour Migration Cloud
# Projet P11 - Big Data Fruits
################################################################################

# =============================================================================
# 1. INSTALLATION AWS CLI
# =============================================================================

# Télécharger et installer AWS CLI v2
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# Vérifier l'installation
aws --version


# =============================================================================
# 2. CONFIGURATION AWS CLI
# =============================================================================

# Configurer avec vos identifiants
aws configure
# AWS Access Key ID: [VOTRE_CLE]
# AWS Secret Access Key: [VOTRE_SECRET]
# Default region: eu-west-1
# Default output format: json

# Vérifier la configuration
aws sts get-caller-identity
aws s3 ls


# =============================================================================
# 3. CRÉATION BUCKET S3
# =============================================================================

# Définir les variables
export BUCKET_NAME="oc-p11-fruits-$(date +%Y%m%d)"
export REGION="eu-west-1"

# Créer le bucket
aws s3 mb s3://${BUCKET_NAME} --region ${REGION}

# Bloquer l'accès public
aws s3api put-public-access-block \
    --bucket ${BUCKET_NAME} \
    --public-access-block-configuration \
    "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"

# Créer la structure de dossiers
aws s3api put-object --bucket ${BUCKET_NAME} --key data/raw/
aws s3api put-object --bucket ${BUCKET_NAME} --key data/features/
aws s3api put-object --bucket ${BUCKET_NAME} --key data/pca/
aws s3api put-object --bucket ${BUCKET_NAME} --key logs/

# Vérifier
aws s3 ls s3://${BUCKET_NAME}/


# =============================================================================
# 4. UPLOAD DU DATASET
# =============================================================================

# Upload Training (peut prendre 10-30 minutes)
aws s3 sync data/raw/fruits-360_dataset/fruits-360/Training/ \
    s3://${BUCKET_NAME}/data/raw/Training/ \
    --region ${REGION} \
    --exclude "*.DS_Store"

# Vérifier l'upload
aws s3 ls s3://${BUCKET_NAME}/data/raw/Training/ --recursive | wc -l

# Afficher la taille
aws s3 ls s3://${BUCKET_NAME}/data/raw/ --recursive --human-readable --summarize


# =============================================================================
# 5. CRÉATION PAIRE DE CLÉS SSH
# =============================================================================

# Définir le nom de la clé
export KEY_NAME="emr-p11-fruits-key"

# Créer la clé
aws ec2 create-key-pair \
    --key-name ${KEY_NAME} \
    --query 'KeyMaterial' \
    --output text \
    --region ${REGION} > ~/.ssh/${KEY_NAME}.pem

# Sécuriser la clé
chmod 400 ~/.ssh/${KEY_NAME}.pem

# Vérifier
ls -l ~/.ssh/${KEY_NAME}.pem


# =============================================================================
# 6. CRÉATION CLUSTER EMR
# =============================================================================

# Définir les variables du cluster
export CLUSTER_NAME="P11-Fruits-BigData-$(date +%Y%m%d)"
export EMR_RELEASE="emr-7.5.0"
export INSTANCE_TYPE="m5.xlarge"

# Créer le cluster (⚠️ COÛTE ~2-3€/heure)
export CLUSTER_ID=$(aws emr create-cluster \
    --name "${CLUSTER_NAME}" \
    --region ${REGION} \
    --release-label ${EMR_RELEASE} \
    --applications Name=Spark Name=JupyterHub Name=Hadoop \
    --instance-groups \
        InstanceGroupType=MASTER,InstanceCount=1,InstanceType=${INSTANCE_TYPE} \
        InstanceGroupType=CORE,InstanceCount=2,InstanceType=${INSTANCE_TYPE} \
    --ec2-attributes KeyName=${KEY_NAME} \
    --use-default-roles \
    --log-uri s3://${BUCKET_NAME}/logs/ \
    --enable-debugging \
    --configurations '[
        {
            "Classification": "spark",
            "Properties": {
                "maximizeResourceAllocation": "true"
            }
        }
    ]' \
    --query 'ClusterId' \
    --output text)

# Afficher l'ID du cluster
echo "Cluster ID: ${CLUSTER_ID}"

# Sauvegarder l'ID
echo ${CLUSTER_ID} > cluster_id.txt


# =============================================================================
# 7. MONITORING DU CLUSTER
# =============================================================================

# Afficher le statut
aws emr describe-cluster --cluster-id ${CLUSTER_ID} --query 'Cluster.Status.State'

# Suivre le statut (répéter toutes les 30s)
watch -n 30 "aws emr describe-cluster --cluster-id ${CLUSTER_ID} --query 'Cluster.Status.State'"

# Récupérer le DNS du master (quand statut = WAITING)
export MASTER_DNS=$(aws emr describe-cluster \
    --cluster-id ${CLUSTER_ID} \
    --query 'Cluster.MasterPublicDnsName' \
    --output text)

echo "Master DNS: ${MASTER_DNS}"


# =============================================================================
# 8. CONNEXION SSH ET TUNNEL
# =============================================================================

# Créer le tunnel SSH vers JupyterHub
# ⚠️ Cette commande bloque le terminal (laisser ouvert)
ssh -i ~/.ssh/${KEY_NAME}.pem \
    -N -L 9443:${MASTER_DNS}:9443 \
    hadoop@${MASTER_DNS}

# Accéder à JupyterHub dans le navigateur:
# URL: https://localhost:9443
# Username: jovyan
# Password: jupyter


# =============================================================================
# 9. COMMANDES UTILES PENDANT L'EXÉCUTION
# =============================================================================

# Lister les fichiers sur S3
aws s3 ls s3://${BUCKET_NAME}/data/ --recursive

# Voir les logs du cluster
aws emr describe-cluster --cluster-id ${CLUSTER_ID}

# Voir les applications du cluster
aws emr list-instances --cluster-id ${CLUSTER_ID}


# =============================================================================
# 10. TÉLÉCHARGEMENT DES RÉSULTATS
# =============================================================================

# Créer les dossiers locaux
mkdir -p data/emr_output/features
mkdir -p data/emr_output/pca

# Télécharger les features
aws s3 sync s3://${BUCKET_NAME}/data/features/ \
    data/emr_output/features/ \
    --region ${REGION}

# Télécharger les résultats PCA
aws s3 sync s3://${BUCKET_NAME}/data/pca/ \
    data/emr_output/pca/ \
    --region ${REGION}

# Vérifier
ls -lh data/emr_output/


# =============================================================================
# 11. ARRÊT DU CLUSTER (⚠️ IMPORTANT !)
# =============================================================================

# Vérifier que les données sont sur S3
aws s3 ls s3://${BUCKET_NAME}/data/pca/ --recursive

# Arrêter le cluster
aws emr terminate-clusters --cluster-ids ${CLUSTER_ID}

# Vérifier l'arrêt
aws emr describe-cluster --cluster-id ${CLUSTER_ID} --query 'Cluster.Status.State'
# Doit afficher: TERMINATING puis TERMINATED


# =============================================================================
# 12. VÉRIFICATION DES COÛTS
# =============================================================================

# Via la console AWS:
# 1. AWS Console > Billing > Bills
# 2. Filtrer par service: EMR, S3, EC2
# 3. Vérifier les coûts du mois en cours


# =============================================================================
# 13. NETTOYAGE COMPLET (APRÈS LE PROJET)
# =============================================================================

# Supprimer tous les fichiers du bucket
aws s3 rm s3://${BUCKET_NAME}/ --recursive

# Supprimer le bucket
aws s3 rb s3://${BUCKET_NAME}

# Supprimer la clé SSH (sur AWS)
aws ec2 delete-key-pair --key-name ${KEY_NAME} --region ${REGION}

# Vérifier
aws s3 ls


# =============================================================================
# VARIABLES À PERSONNALISER
# =============================================================================

# À définir selon votre configuration:
# export BUCKET_NAME="votre-bucket-name"
# export REGION="eu-west-1"  # ou eu-central-1
# export KEY_NAME="votre-key-name"
# export CLUSTER_ID="j-XXXXXXXXXXXXX"
# export MASTER_DNS="ec2-XX-XX-XX-XX.eu-west-1.compute.amazonaws.com"


# =============================================================================
# ALTERNATIVE: UTILISER LE SCRIPT HELPER
# =============================================================================

# Le script helper automatise toutes ces commandes
./scripts/aws_setup.sh help

# Commandes principales:
./scripts/aws_setup.sh create-bucket
./scripts/aws_setup.sh upload-dataset
./scripts/aws_setup.sh create-cluster
./scripts/aws_setup.sh status
./scripts/aws_setup.sh connect
./scripts/aws_setup.sh download-results
./scripts/aws_setup.sh terminate


################################################################################
# FIN
################################################################################