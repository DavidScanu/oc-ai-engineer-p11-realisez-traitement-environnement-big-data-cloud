# Quick Start - Migration AWS (5 √©tapes)

**Guide complet** : Voir [GUIDE_MIGRATION_AWS.md](GUIDE_MIGRATION_AWS.md)

---

## üìã Pr√©requis

- ‚úÖ Compte AWS actif
- ‚úÖ Pipeline local valid√© (100 images test√©es)
- ‚úÖ Dataset local disponible

---

## üöÄ D√©marrage Rapide (30 minutes setup + 3h ex√©cution)

### √âtape 1 : Installer AWS CLI (5 min)

```bash
# T√©l√©charger et installer
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
unzip awscliv2.zip
sudo ./aws/install

# V√©rifier
aws --version
```

### √âtape 2 : Configurer AWS CLI (5 min)

1. **Cr√©er les cl√©s IAM** :
   - Console AWS ‚Üí IAM ‚Üí Utilisateurs ‚Üí Votre user ‚Üí S√©curit√©
   - "Cr√©er une cl√© d'acc√®s" ‚Üí CLI
   - **Noter** : Access Key + Secret Key

2. **Configurer** :
```bash
aws configure
# AWS Access Key ID: VOTRE_CLE
# AWS Secret Access Key: VOTRE_CLE_SECRETE
# Default region: eu-west-1
# Default output format: json
```

### √âtape 3 : Cr√©er le bucket S3 et uploader le dataset (30 min)

**Option A - Script automatique (recommand√©)** :
```bash
# Cr√©er le bucket
./scripts/aws_setup.sh create-bucket

# Uploader le dataset (10-30 min)
./scripts/aws_setup.sh upload-dataset
```

**Option B - Commandes manuelles** :
```bash
# Cr√©er le bucket
BUCKET_NAME="oc-p11-fruits-$(date +%Y%m%d)"
aws s3 mb s3://${BUCKET_NAME} --region eu-west-1

# Uploader
aws s3 sync data/raw/fruits-360_dataset/fruits-360/Training/ \
    s3://${BUCKET_NAME}/data/raw/Training/
```

### √âtape 4 : Cr√©er et lancer le cluster EMR (15 min)

**Option A - Script automatique (recommand√©)** :
```bash
# Cr√©er le cluster (co√ªt: ~2-3‚Ç¨/h)
./scripts/aws_setup.sh create-cluster

# Suivre le d√©marrage
./scripts/aws_setup.sh status
```

**Option B - Commande manuelle** :
```bash
# Cr√©er la cl√© SSH
aws ec2 create-key-pair --key-name emr-key \
    --query 'KeyMaterial' --output text > ~/.ssh/emr-key.pem
chmod 400 ~/.ssh/emr-key.pem

# Cr√©er le cluster
aws emr create-cluster \
    --name "P11-Fruits-BigData" \
    --region eu-west-1 \
    --release-label emr-7.5.0 \
    --applications Name=Spark Name=JupyterHub Name=Hadoop \
    --instance-groups \
        InstanceGroupType=MASTER,InstanceCount=1,InstanceType=m5.xlarge \
        InstanceGroupType=CORE,InstanceCount=2,InstanceType=m5.xlarge \
    --ec2-attributes KeyName=emr-key \
    --use-default-roles
```

### √âtape 5 : G√©n√©rer le notebook EMR et l'uploader (5 min)

1. **G√©n√©rer le notebook EMR adapt√©** :
```bash
# Convertir automatiquement le notebook local pour EMR
python3 scripts/convert_notebook_to_emr.py
```

Cela cr√©e `notebooks/p11-david-scanu-EMR-production.ipynb` avec :
- ‚úÖ Chemins S3 au lieu de chemins locaux
- ‚úÖ Configuration Spark pour EMR (pas de `.master("local[*]")`)
- ‚úÖ Sauvegardes vers S3 au lieu du disque local

2. **Cr√©er le tunnel SSH** :
```bash
./scripts/aws_setup.sh connect
```

3. **Acc√©der √† JupyterHub** :
   - Navigateur : https://localhost:9443
   - Username : `jovyan`
   - Password : `jupyter`

4. **Uploader le notebook EMR** :
   - Clic sur "Upload" dans JupyterHub
   - S√©lectionner `notebooks/p11-david-scanu-EMR-production.ipynb`
   - Clic sur "Upload" pour confirmer

5. **Installer TensorFlow sur le cluster** (dans le notebook EMR, cellule 1) :
```python
import sys
!{sys.executable} -m pip install tensorflow==2.16.1 pillow --quiet
```

6. **Ex√©cuter le pipeline** :
   - **Test rapide** : 100 images (~10 min) - MODE MINI activ√© par d√©faut
   - **Dataset complet** : 67,692 images (~3-4h) - Changer `TEST_MODE = "full"`

---

## üì• R√©cup√©rer les R√©sultats et Arr√™ter

### T√©l√©charger les r√©sultats

```bash
# Via le script
./scripts/aws_setup.sh download-results

# Ou manuellement
aws s3 sync s3://${BUCKET_NAME}/data/pca/ data/emr_output/pca/
```

### ‚ö†Ô∏è IMPORTANT : Arr√™ter le cluster

```bash
# Via le script
./scripts/aws_setup.sh terminate

# V√©rifier l'arr√™t
./scripts/aws_setup.sh status
```

**üî¥ NE PAS OUBLIER** sinon facturation continue !

---

## üí∞ Co√ªts Estim√©s

| Ressource | Dur√©e | Co√ªt |
|-----------|-------|------|
| EMR (1 master + 2 workers m5.xlarge) | 3h | ~2.30‚Ç¨ |
| S3 stockage 2 GB | 1 mois | ~0.05‚Ç¨ |
| **TOTAL** | | **~2.35‚Ç¨** |

---

## üÜò D√©pannage Rapide

### AWS CLI non trouv√© apr√®s installation
```bash
export PATH=$PATH:/usr/local/bin
# Ou relancer le terminal
```

### Connexion SSH refus√©e
```bash
# Ouvrir le port SSH pour votre IP
MY_IP=$(curl -s https://checkip.amazonaws.com)
aws ec2 authorize-security-group-ingress \
    --group-id ${SECURITY_GROUP} \
    --protocol tcp --port 22 \
    --cidr ${MY_IP}/32
```

### TensorFlow manquant sur EMR
```python
# Dans le notebook EMR
import sys
!{sys.executable} -m pip install tensorflow==2.16.1
```

---

## üìö Ressources

- **Guide complet** : [GUIDE_MIGRATION_AWS.md](GUIDE_MIGRATION_AWS.md)
- **Notebook local** : [notebooks/p11-david-scanu-local-development.ipynb](../notebooks/p11-david-scanu-local-development.ipynb)
- **Script helper** : [scripts/aws_setup.sh](../scripts/aws_setup.sh)

---

## üéØ Checklist Rapide

### Setup (30 min)
- [ ] AWS CLI install√© et configur√©
- [ ] Bucket S3 cr√©√© en r√©gion EU
- [ ] Dataset upload√© sur S3

### Ex√©cution (3-4h)
- [ ] Cluster EMR lanc√©
- [ ] Tunnel SSH cr√©√©
- [ ] JupyterHub accessible
- [ ] Notebook cr√©√© avec code adapt√©
- [ ] Pipeline ex√©cut√© avec succ√®s

### Finalisation (30 min)
- [ ] R√©sultats t√©l√©charg√©s
- [ ] Cluster EMR arr√™t√© ‚ö†Ô∏è
- [ ] Co√ªts v√©rifi√©s

---

**Derni√®re mise √† jour** : 7 Novembre 2025