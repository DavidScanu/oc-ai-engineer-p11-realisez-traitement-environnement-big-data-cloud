# Migration AWS - Projet P11 Big Data Fruits

**Statut** : âœ… Pipeline local validÃ© - PrÃªt pour migration AWS
**Date** : 7 Novembre 2025

---

## ğŸ“‹ RÃ©sumÃ© du Projet

Ce projet implÃ©mente un pipeline de traitement Big Data pour la classification d'images de fruits en utilisant :
- **PySpark** pour le traitement distribuÃ©
- **TensorFlow MobileNetV2** pour l'extraction de features
- **PCA** pour la rÃ©duction de dimensionnalitÃ©
- **AWS EMR + S3** pour l'infrastructure cloud

### Ce qui a Ã©tÃ© rÃ©alisÃ© (Phase 2 - Local)

âœ… **Pipeline PySpark complet** :
- Chargement et traitement de 100 images validÃ©
- Broadcast des poids TensorFlow fonctionnel (260 tenseurs, 8.61 MB)
- Extraction de features : 1280 dimensions par image
- PCA : rÃ©duction 1280 â†’ 200 dimensions
- Sauvegarde multi-format (Parquet + CSV)

âœ… **Documentation complÃ¨te** :
- Notebook bien structurÃ© avec 8 sections
- 4 modes de test (MINI, SINGLE_CLASS, APPLES, FULL)
- Code commentÃ© et optimisÃ©

### Prochaine Ã©tape : Migration AWS (Phase 3)

ğŸ¯ **Objectif** : DÃ©ployer le pipeline sur AWS EMR pour traiter les 67,692 images du dataset complet

---

## ğŸš€ DÃ©marrage Rapide

### Option 1 : Guide Rapide (5 Ã©tapes - 30 min)

Suivez le guide de dÃ©marrage rapide :

```bash
cat documentation/QUICKSTART_AWS.md
```

**Les 5 Ã©tapes** :
1. Installer AWS CLI (5 min)
2. Configurer AWS CLI (5 min)
3. CrÃ©er bucket S3 + uploader dataset (30 min)
4. CrÃ©er cluster EMR (15 min)
5. ExÃ©cuter le pipeline (3-4h)

### Option 2 : Script Automatique (recommandÃ©)

Utilisez le script helper pour automatiser les commandes :

```bash
# Afficher l'aide
./scripts/aws_setup.sh help

# Ã‰tapes principales
./scripts/aws_setup.sh create-bucket        # CrÃ©er le bucket S3
./scripts/aws_setup.sh upload-dataset       # Upload dataset
./scripts/aws_setup.sh create-cluster       # CrÃ©er le cluster EMR
./scripts/aws_setup.sh status               # VÃ©rifier le statut
./scripts/aws_setup.sh connect              # Se connecter (tunnel SSH)
./scripts/aws_setup.sh download-results     # TÃ©lÃ©charger les rÃ©sultats
./scripts/aws_setup.sh terminate            # ArrÃªter le cluster
```

### Option 3 : Guide Complet (dÃ©taillÃ©)

Pour des instructions dÃ©taillÃ©es avec toutes les explications :

```bash
cat documentation/GUIDE_MIGRATION_AWS.md
```

---

## ğŸ“ Structure du Projet

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ fruits-360_dataset/        # Dataset local (67,692 images)
â”‚   â”œâ”€â”€ features/                      # Features extraites (local)
â”‚   â”œâ”€â”€ pca/                           # RÃ©sultats PCA (local)
â”‚   â””â”€â”€ emr_output/                    # RÃ©sultats tÃ©lÃ©chargÃ©s depuis AWS
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ p11-david-scanu-local-development.ipynb    # âœ… Pipeline validÃ©
â”‚   â””â”€â”€ alternant/
â”‚       â””â”€â”€ P8_Notebook_Linux_EMR_PySpark_V1.0.ipynb
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ aws_setup.sh                   # ğŸ› ï¸ Script helper AWS
â”‚
â””â”€â”€ documentation/
    â”œâ”€â”€ PLAN_ACTION.md                 # Plan dÃ©taillÃ© du projet
    â”œâ”€â”€ GUIDE_MIGRATION_AWS.md         # ğŸ“˜ Guide complet AWS
    â”œâ”€â”€ QUICKSTART_AWS.md              # âš¡ DÃ©marrage rapide
    â”œâ”€â”€ DATASET_INFO.md                # Infos sur le dataset
    â””â”€â”€ MISSION.md                     # Contexte du projet
```

---

## ğŸ¯ Pipeline PySpark

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Images S3      â”‚ â”€â”
â”‚  67,692 images  â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PySpark   â”‚
              â”‚   Cluster   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚Worker 1â”‚  â”‚Worker 2â”‚  â”‚Worker 3â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚  Broadcast  â”‚
              â”‚  Weights    â”‚
              â”‚  (8.61 MB)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  MobileNetV2    â”‚
              â”‚  Feature Extractâ”‚
              â”‚  (1280 dims)    â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚     PCA     â”‚
              â”‚  (200 dims) â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Results S3  â”‚
              â”‚ Parquet+CSV â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants ClÃ©s

1. **Broadcast TensorFlow** :
   - Optimisation cruciale pour Ã©viter de recharger le modÃ¨le sur chaque worker
   - 260 tenseurs (~8.61 MB) distribuÃ©s une seule fois
   - Gain de performance significatif

2. **Pandas UDF** :
   - Traitement par batch d'images
   - Utilisation d'Apache Arrow pour la sÃ©rialisation
   - ParallÃ©lisation automatique par Spark

3. **PCA distribuÃ©** :
   - `pyspark.ml.feature.PCA`
   - RÃ©duction 1280 â†’ 200 dimensions
   - Conservation excellente de la variance

---

## ğŸ’° Estimation des CoÃ»ts AWS

| Composant | Configuration | DurÃ©e | CoÃ»t |
|-----------|---------------|-------|------|
| EMR Master | m5.xlarge | 3h | ~0.70â‚¬ |
| EMR Core (x2) | m5.xlarge | 3h | ~1.40â‚¬ |
| EMR Surcharge | - | 3h | ~0.20â‚¬ |
| S3 Stockage | 2 GB | 1 mois | ~0.05â‚¬ |
| **TOTAL** | | | **~2.35â‚¬** |

**âš ï¸ Note** : Si le traitement du dataset complet prend 4h, prÃ©voir ~3-4â‚¬

---

## ğŸ“Š Performances Attendues

### Tests Locaux (rÃ©fÃ©rence)

| Mode | Images | Temps Features | Temps PCA | Total |
|------|--------|----------------|-----------|-------|
| MINI | 100 | ~2 min | ~4 sec | ~2-3 min |
| MINI | 500 | ~8 min | ~30 sec | ~8-10 min |

### Projections AWS EMR (3 workers m5.xlarge)

| Dataset | Images | Temps EstimÃ© | CoÃ»t EstimÃ© |
|---------|--------|--------------|-------------|
| Apples | 6,404 | ~1h | ~1â‚¬ |
| Full | 67,692 | ~3-4h | ~2.35-3â‚¬ |

**Facteurs d'accÃ©lÃ©ration** :
- ParallÃ©lisation sur 3 workers
- Broadcast Ã©vite les rechargements rÃ©seau
- S3A filesystem optimisÃ© pour EMR 7.x

---

## âœ… Checklist Migration

### PrÃ©requis
- [ ] Compte AWS actif avec carte de crÃ©dit
- [ ] Dataset local tÃ©lÃ©chargÃ© et extrait
- [ ] Pipeline local testÃ© et validÃ©

### Configuration AWS (30 min)
- [ ] AWS CLI installÃ©
- [ ] ClÃ©s IAM crÃ©Ã©es et configurÃ©es
- [ ] RÃ©gion EU configurÃ©e (eu-west-1 ou eu-central-1)

### Bucket S3 (30 min)
- [ ] Bucket crÃ©Ã© en rÃ©gion europÃ©enne
- [ ] AccÃ¨s public bloquÃ©
- [ ] Dataset uploadÃ© (67,692 images)
- [ ] Structure de dossiers crÃ©Ã©e

### Cluster EMR (15 min + 3-4h exÃ©cution)
- [ ] Paire de clÃ©s SSH crÃ©Ã©e
- [ ] Cluster EMR lancÃ© (EMR 7.5.0, Spark 3.5.x)
- [ ] Cluster en Ã©tat WAITING
- [ ] Tunnel SSH crÃ©Ã© vers JupyterHub

### ExÃ©cution (3-4h)
- [ ] JupyterHub accessible (https://localhost:9443)
- [ ] Notebook crÃ©Ã© avec code adaptÃ©
- [ ] Test rapide 100 images rÃ©ussi
- [ ] Dataset complet traitÃ©
- [ ] RÃ©sultats vÃ©rifiÃ©s sur S3

### Finalisation (30 min)
- [ ] RÃ©sultats tÃ©lÃ©chargÃ©s localement
- [ ] Cluster EMR arrÃªtÃ© (Ã©tat TERMINATED)
- [ ] CoÃ»ts vÃ©rifiÃ©s dans AWS Billing

---

## ğŸ†˜ Support et Documentation

### Guides disponibles

1. **[QUICKSTART_AWS.md](documentation/QUICKSTART_AWS.md)** - DÃ©marrage rapide en 5 Ã©tapes
2. **[GUIDE_MIGRATION_AWS.md](documentation/GUIDE_MIGRATION_AWS.md)** - Guide complet dÃ©taillÃ©
3. **[PLAN_ACTION.md](documentation/PLAN_ACTION.md)** - Plan global du projet
4. **[aws_setup.sh](scripts/aws_setup.sh)** - Script d'automatisation

### Notebook de rÃ©fÃ©rence

- **[p11-david-scanu-local-development.ipynb](notebooks/p11-david-scanu-local-development.ipynb)** - Pipeline validÃ© localement

### Ressources AWS

- [AWS EMR Documentation](https://docs.aws.amazon.com/emr/)
- [PySpark on EMR](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark.html)
- [EMR Pricing Calculator](https://aws.amazon.com/emr/pricing/)

---

## ğŸ”’ SÃ©curitÃ© et ConformitÃ©

### RGPD

âœ… **RÃ©gion europÃ©enne** : Toutes les ressources sont crÃ©Ã©es en `eu-west-1` (Irlande) ou `eu-central-1` (Francfort)

âœ… **AccÃ¨s S3** : Bucket configurÃ© pour bloquer l'accÃ¨s public

âœ… **Chiffrement** : DonnÃ©es en transit chiffrÃ©es (HTTPS, SSH)

### Bonnes Pratiques

- ClÃ©s SSH avec permissions 400
- ClÃ©s IAM avec permissions minimales requises
- Security groups restrictifs (seulement votre IP)
- ArrÃªt systÃ©matique du cluster aprÃ¨s utilisation

---

## ğŸ“ Livrables du Projet

AprÃ¨s la migration AWS, les livrables finaux seront :

1. **Notebook production** : `David_Scanu_1_notebook_112025.ipynb`
   - Pipeline complet exÃ©cutÃ© sur AWS EMR
   - Commentaires dÃ©taillÃ©s
   - RÃ©sultats validÃ©s

2. **Documentation des images** : `David_Scanu_2_images_112025.pdf`
   - Lien vers le bucket S3
   - Screenshots de l'exÃ©cution sur EMR
   - MÃ©triques Spark UI

3. **PrÃ©sentation** : `David_Scanu_3_presentation_112025.pdf`
   - Architecture Big Data
   - Pipeline PySpark expliquÃ©
   - RÃ©sultats et performances

---

## ğŸ“ Contact

**Projet** : OpenClassrooms - Parcours AI Engineer - Projet 11
**Ã‰tudiant** : David Scanu
**Date** : Novembre 2025

---

**DerniÃ¨re mise Ã  jour** : 7 Novembre 2025