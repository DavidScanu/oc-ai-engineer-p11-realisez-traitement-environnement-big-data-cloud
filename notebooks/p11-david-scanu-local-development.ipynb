{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 11 - Big Data Cloud : Classification de Fruits\n",
    "\n",
    "**Auteur** : David Scanu  \n",
    "**Date** : Octobre 2025  \n",
    "**Objectif** : D\u00e9veloppement local du pipeline PySpark avec broadcast TensorFlow et PCA\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udccb Sommaire\n",
    "\n",
    "1. [Setup et Configuration](#1-setup-et-configuration)\n",
    "2. [Initialisation PySpark](#2-initialisation-pyspark)\n",
    "3. [Chargement et Exploration des Donn\u00e9es](#3-chargement-et-exploration-des-donn\u00e9es)\n",
    "4. [Extraction de Features avec TensorFlow](#4-extraction-de-features-avec-tensorflow)\n",
    "5. [Broadcast des Poids du Mod\u00e8le](#5-broadcast-des-poids-du-mod\u00e8le)\n",
    "6. [R\u00e9duction de Dimension avec PCA](#6-r\u00e9duction-de-dimension-avec-pca)\n",
    "7. [Tests et Validation](#7-tests-et-validation)\n",
    "\n",
    "---\n",
    "\n",
    "## \u26a0\ufe0f Important\n",
    "\n",
    "Ce notebook est con\u00e7u pour le **d\u00e9veloppement et test en local**.\n",
    "\n",
    "- \u2705 Tester et valider le code ici avant migration cloud\n",
    "- \u2705 Utiliser un subset des donn\u00e9es pour it\u00e9rer rapidement\n",
    "- \u274c Ne PAS utiliser AWS EMR \u00e0 ce stade (co\u00fbts)\n",
    "\n",
    "Une fois valid\u00e9 localement, le code sera migr\u00e9 vers AWS EMR JupyterHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup et Configuration\n",
    "\n",
    "### 1.1 V\u00e9rification de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V\u00e9rifier les versions des packages\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import pyspark\n",
    "    print(f\"PySpark version: {pyspark.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0\ufe0f PySpark n'est pas install\u00e9\")\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0\ufe0f TensorFlow n'est pas install\u00e9\")\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "    print(f\"PIL/Pillow: OK\")\n",
    "except ImportError:\n",
    "    print(\"\u26a0\ufe0f Pillow n'est pas install\u00e9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Installation des d\u00e9pendances (si n\u00e9cessaire)\n",
    "\n",
    "**Note** : D\u00e9commenter et ex\u00e9cuter si les packages ne sont pas install\u00e9s.\n",
    "\n",
    "```bash\n",
    "pip install pyspark==3.5.0 tensorflow==2.16.1 pillow pandas numpy pyarrow\n",
    "```\n",
    "\n",
    "**Pr\u00e9requis** : Java JDK 11 ou 17 doit \u00eatre install\u00e9 pour PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark imports\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, pandas_udf, element_at, split\n",
    "from pyspark.sql.types import ArrayType, FloatType, StructType, StructField, StringType\n",
    "from pyspark.ml.feature import PCA, VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# TensorFlow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# Autres imports\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\u2705 Imports r\u00e9ussis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Configuration des chemins\n",
    "\n",
    "Adapter ces chemins selon votre environnement local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins locaux\n",
    "PROJECT_ROOT = Path(os.getcwd()).parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "FEATURES_DIR = DATA_DIR / \"features\"\n",
    "PCA_DIR = DATA_DIR / \"pca\"\n",
    "\n",
    "# Cr\u00e9er les dossiers s'ils n'existent pas\n",
    "for directory in [DATA_DIR, RAW_DATA_DIR, FEATURES_DIR, PCA_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\ud83d\udcc1 Dossier projet: {PROJECT_ROOT}\")\n",
    "print(f\"\ud83d\udcc1 Dossier donn\u00e9es: {DATA_DIR}\")\n",
    "print(f\"\ud83d\udcc1 Donn\u00e9es brutes: {RAW_DATA_DIR}\")\n",
    "print(f\"\ud83d\udcc1 Features: {FEATURES_DIR}\")\n",
    "print(f\"\ud83d\udcc1 PCA: {PCA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Initialisation PySpark\n",
    "\n",
    "### 2.1 Cr\u00e9ation de la SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration PySpark pour d\u00e9veloppement local\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"P11-Fruits-Local-Development\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configuration du niveau de log\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# R\u00e9cup\u00e9rer le SparkContext pour le broadcast\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(f\"\u2705 SparkSession cr\u00e9\u00e9e\")\n",
    "print(f\"   Version Spark: {spark.version}\")\n",
    "print(f\"   Master: {spark.sparkContext.master}\")\n",
    "print(f\"   App Name: {spark.sparkContext.appName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Chargement et Exploration des Donn\u00e9es\n",
    "\n",
    "### 3.1 T\u00e9l\u00e9chargement du dataset (si n\u00e9cessaire)\n",
    "\n",
    "**Option 1 - T\u00e9l\u00e9chargement depuis Kaggle** :\n",
    "```bash\n",
    "# Installer Kaggle CLI si n\u00e9cessaire\n",
    "pip install kaggle\n",
    "\n",
    "# T\u00e9l\u00e9charger le dataset\n",
    "kaggle datasets download -d moltean/fruits -p data/raw/ --unzip\n",
    "```\n",
    "\n",
    "**Option 2 - T\u00e9l\u00e9chargement depuis le lien direct** :\n",
    "```bash\n",
    "# T\u00e9l\u00e9charger et extraire\n",
    "wget https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P8/fruits.zip -P data/raw/\n",
    "unzip data/raw/fruits.zip -d data/raw/\n",
    "```\n",
    "\n",
    "**Option 3 - Subset pour tests rapides** :\n",
    "Utiliser uniquement quelques classes pour tester le code rapidement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Statistiques du dataset\n\nLe dataset Fruits-360 contient deux versions:\n- **fruits-360_dataset**: Images 100x100 pixels (utilis\u00e9 ici)\n- **fruits-360-original-size**: Images en tailles originales\n\n**Contenu du dataset 100x100**:\n- Training: 67,692 images, 131 classes\n- Test: 22,688 images\n\nPour les tests locaux, il est recommand\u00e9 de commencer avec un subset (par exemple les pommes) avant de traiter tout le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u2705 Dataset t\u00e9l\u00e9charg\u00e9 et extrait dans data/raw/\n\n# Structure du dataset:\n# data/raw/\n#   \u251c\u2500\u2500 fruits-360_dataset/fruits-360/\n#   \u2502   \u251c\u2500\u2500 Training/ (67,692 images, 131 classes)\n#   \u2502   \u2514\u2500\u2500 Test/ (22,688 images)\n#   \u2514\u2500\u2500 fruits-360-original-size/ (tailles originales)\n\n# Pour le d\u00e9veloppement, on utilise le dataset 100x100 (fruits-360_dataset)\nIMAGES_PATH = str(RAW_DATA_DIR / \"fruits-360_dataset\" / \"fruits-360\" / \"Training\")\nTEST_IMAGES_PATH = str(RAW_DATA_DIR / \"fruits-360_dataset\" / \"fruits-360\" / \"Test\")\n\nprint(f\"\ud83d\udcc2 Chemin Training: {IMAGES_PATH}\")\nprint(f\"   Existe: {os.path.exists(IMAGES_PATH)}\")\nprint(f\"\ud83d\udcc2 Chemin Test: {TEST_IMAGES_PATH}\")\nprint(f\"   Existe: {os.path.exists(TEST_IMAGES_PATH)}\")\n\n# Compter les images et classes\nif os.path.exists(IMAGES_PATH):\n    classes = [d for d in os.listdir(IMAGES_PATH) if os.path.isdir(os.path.join(IMAGES_PATH, d))]\n    print(f\"\\n\ud83d\udcca Statistiques:\")\n    print(f\"   Nombre de classes: {len(classes)}\")\n    print(f\"   Exemples de classes: {', '.join(classes[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Chargement des images avec PySpark\n",
    "\n",
    "Inspir\u00e9 du code de l'alternant, nous allons charger les images en utilisant `binaryFiles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les images depuis le syst\u00e8me de fichiers local\n# Pour AWS EMR, remplacer par: s3://bucket-name/path/to/images/*/*.jpg\n\n# OPTION 1: Subset pour tests rapides (recommand\u00e9 pour d\u00e9buter)\n# Charger seulement quelques classes de pommes pour tester rapidement\nimage_path = f\"file://{IMAGES_PATH}/Apple*/*.jpg\"\nprint(f\"\ud83d\udd0d Mode: SUBSET (Apple* classes seulement)\")\n\n# OPTION 2: Toutes les images (67,692 images - peut \u00eatre long ~15-30 min)\n# D\u00e9commenter pour traiter tout le dataset:\n# image_path = f\"file://{IMAGES_PATH}/*/*.jpg\"\n# print(f\"\ud83d\udd0d Mode: DATASET COMPLET (toutes les classes)\")\n\nprint(f\"\ud83d\udd0d Pattern de recherche: {image_path}\")\n\n# Charger les images avec PySpark\nprint(\"\u23f3 Chargement des images...\")\ndf_images = spark.read.format(\"binaryFile\").load(image_path)\n\nprint(f\"\u2705 {df_images.count()} images charg\u00e9es\")\nprint(f\"\\nSch\u00e9ma:\")\ndf_images.printSchema()\nprint(f\"\\nAper\u00e7u:\")\ndf_images.show(5, truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Extraction du label depuis le chemin\n",
    "\n",
    "Le nom de la classe (label) est dans le nom du dossier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire le label depuis le chemin du fichier\n# Exemple: file:///path/to/Training/Apple Braeburn/image_001.jpg\n# Label: Apple Braeburn\n\ndf_with_labels = df_images.withColumn(\n    \"label\",\n    element_at(split(col(\"path\"), \"/\"), -2)\n)\n\nprint(f\"\u2705 Labels extraits\")\nprint(f\"\\nAper\u00e7u des donn\u00e9es:\")\ndf_with_labels.select(\"path\", \"label\").show(10, truncate=60)\n\n# Compter les images par classe\nprint(f\"\\n\ud83d\udcca Distribution des classes:\")\nlabel_counts = df_with_labels.groupBy(\"label\").count().orderBy(\"label\")\nlabel_counts.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Extraction de Features avec TensorFlow\n",
    "\n",
    "### 4.1 Pr\u00e9paration du mod\u00e8le MobileNetV2\n",
    "\n",
    "Nous utilisons MobileNetV2 pr\u00e9-entra\u00een\u00e9 sur ImageNet, sans la couche de classification (include_top=False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le mod\u00e8le MobileNetV2 pour l'extraction de features\n",
    "# include_top=False : on retire la couche de classification\n",
    "# pooling='avg' : on applique un average pooling global\n",
    "# Sortie: vecteur de 1280 features par image\n",
    "\n",
    "model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    pooling='avg'\n",
    ")\n",
    "\n",
    "print(\"\u2705 Mod\u00e8le MobileNetV2 charg\u00e9\")\n",
    "print(f\"   Input shape: {model.input_shape}\")\n",
    "print(f\"   Output shape: {model.output_shape}\")\n",
    "print(f\"   Dimension des features: {model.output_shape[1]}\")\n",
    "\n",
    "# Afficher le r\u00e9sum\u00e9 du mod\u00e8le\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Broadcast des Poids du Mod\u00e8le\n",
    "\n",
    "### 5.1 Pourquoi broadcaster les poids ?\n",
    "\n",
    "**Probl\u00e8me** : Sans broadcast, chaque worker Spark recharge le mod\u00e8le MobileNetV2 depuis internet ou disque, ce qui :\n",
    "- Consomme beaucoup de bande passante\n",
    "- Augmente le temps d'ex\u00e9cution\n",
    "- Augmente la consommation m\u00e9moire\n",
    "\n",
    "**Solution** : Utiliser `sc.broadcast()` pour distribuer les poids une seule fois \u00e0 tous les workers.\n",
    "\n",
    "### 5.2 Extraction et broadcast des poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les poids du mod\u00e8le\n",
    "model_weights = model.get_weights()\n",
    "\n",
    "print(f\"\ud83d\udce6 Nombre de tenseurs de poids: {len(model_weights)}\")\n",
    "print(f\"\ud83d\udce6 Taille approximative en m\u00e9moire: {sum([w.nbytes for w in model_weights]) / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Broadcaster les poids \u00e0 tous les workers\n",
    "broadcast_weights = sc.broadcast(model_weights)\n",
    "\n",
    "print(\"\u2705 Poids du mod\u00e8le broadcast\u00e9s\")\n",
    "print(f\"   Broadcast variable ID: {broadcast_weights.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 D\u00e9finition de la Pandas UDF avec broadcast\n",
    "\n",
    "La Pandas UDF permet d'appliquer une fonction sur des batches de donn\u00e9es de mani\u00e8re distribu\u00e9e.\n",
    "\n",
    "**Important** : Le mod\u00e8le doit \u00eatre reconstruit dans chaque worker avec les poids broadcast\u00e9s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D\u00e9finir le sch\u00e9ma de sortie (array de 1280 floats)\n",
    "features_schema = ArrayType(FloatType())\n",
    "\n",
    "# D\u00e9finir la Pandas UDF\n",
    "@pandas_udf(features_schema)\n",
    "def extract_features_udf(content_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Extrait les features d'images en utilisant MobileNetV2.\n",
    "    \n",
    "    Cette fonction est ex\u00e9cut\u00e9e sur chaque worker Spark.\n",
    "    Elle reconstruit le mod\u00e8le avec les poids broadcast\u00e9s.\n",
    "    \n",
    "    Args:\n",
    "        content_series: S\u00e9rie Pandas contenant les donn\u00e9es binaires des images\n",
    "        \n",
    "    Returns:\n",
    "        S\u00e9rie Pandas contenant les features extraites (arrays de 1280 floats)\n",
    "    \"\"\"\n",
    "    # Reconstruire le mod\u00e8le dans le worker\n",
    "    # weights=None car on va charger les poids broadcast\u00e9s\n",
    "    local_model = MobileNetV2(\n",
    "        weights=None,\n",
    "        include_top=False,\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    # Charger les poids broadcast\u00e9s\n",
    "    local_model.set_weights(broadcast_weights.value)\n",
    "    \n",
    "    def process_image(content):\n",
    "        \"\"\"\n",
    "        Traite une image individuelle.\n",
    "        \n",
    "        Args:\n",
    "            content: Donn\u00e9es binaires de l'image\n",
    "            \n",
    "        Returns:\n",
    "            Array de features (1280 floats) ou None si erreur\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Charger l'image depuis les bytes\n",
    "            img = Image.open(io.BytesIO(content))\n",
    "            \n",
    "            # Convertir en RGB si n\u00e9cessaire\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Redimensionner \u00e0 la taille attendue par MobileNetV2 (224x224)\n",
    "            img = img.resize((224, 224))\n",
    "            \n",
    "            # Convertir en array numpy\n",
    "            img_array = img_to_array(img)\n",
    "            \n",
    "            # Ajouter la dimension batch (1, 224, 224, 3)\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            \n",
    "            # Pr\u00e9traiter selon les attentes de MobileNetV2\n",
    "            img_array = preprocess_input(img_array)\n",
    "            \n",
    "            # Extraire les features\n",
    "            features = local_model.predict(img_array, verbose=0)\n",
    "            \n",
    "            # Retourner le vecteur de features (1280,)\n",
    "            return features[0].tolist()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du traitement de l'image: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Appliquer le traitement sur toutes les images du batch\n",
    "    return content_series.apply(process_image)\n",
    "\n",
    "print(\"\u2705 Pandas UDF d\u00e9finie\")\n",
    "print(\"   Fonction: extract_features_udf\")\n",
    "print(\"   Utilise les poids broadcast\u00e9s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Application de l'extraction de features\n",
    "\n",
    "**Note** : Cette \u00e9tape peut prendre du temps selon le nombre d'images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer l'extraction de features\n",
    "# df_features = df_with_labels.withColumn(\n",
    "#     \"features\",\n",
    "#     extract_features_udf(col(\"content\"))\n",
    "# )\n",
    "\n",
    "# # Filtrer les images o\u00f9 l'extraction a \u00e9chou\u00e9\n",
    "# df_features = df_features.filter(col(\"features\").isNotNull())\n",
    "\n",
    "# print(f\"\u2705 Features extraites pour {df_features.count()} images\")\n",
    "# df_features.select(\"path\", \"label\", \"features\").show(5, truncate=60)\n",
    "\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter une fois les images charg\u00e9es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Sauvegarde des features (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les features en format Parquet (efficace pour PySpark)\n",
    "# features_output_path = str(FEATURES_DIR / \"mobilenetv2_features\")\n",
    "# df_features.write.mode(\"overwrite\").parquet(features_output_path)\n",
    "\n",
    "# print(f\"\u2705 Features sauvegard\u00e9es: {features_output_path}\")\n",
    "\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter une fois les features extraites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. R\u00e9duction de Dimension avec PCA\n",
    "\n",
    "### 6.1 Pr\u00e9paration des donn\u00e9es pour PCA\n",
    "\n",
    "PySpark PCA attend un vecteur dense en entr\u00e9e. Il faut donc transformer notre array de features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on recharge depuis Parquet:\n",
    "# df_features = spark.read.parquet(str(FEATURES_DIR / \"mobilenetv2_features\"))\n",
    "\n",
    "# Convertir l'array de features en vecteur dense\n",
    "# PySpark ML attend un VectorUDT\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# UDF pour convertir array -> vecteur dense\n",
    "array_to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())\n",
    "\n",
    "# df_for_pca = df_features.withColumn(\n",
    "#     \"features_vector\",\n",
    "#     array_to_vector(col(\"features\"))\n",
    "# )\n",
    "\n",
    "# df_for_pca.select(\"label\", \"features_vector\").show(5, truncate=60)\n",
    "\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter une fois les features extraites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Application de la PCA\n",
    "\n",
    "La PCA r\u00e9duit la dimensionnalit\u00e9 de 1280 \u00e0 k composantes principales.\n",
    "\n",
    "**Choix de k** :\n",
    "- k=100 : R\u00e9duction forte, moins d'information\n",
    "- k=200 : Bon compromis\n",
    "- k=500 : R\u00e9duction mod\u00e9r\u00e9e, plus d'information\n",
    "\n",
    "On peut aussi analyser la variance expliqu\u00e9e pour choisir k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de composantes principales\n",
    "K_COMPONENTS = 200\n",
    "\n",
    "# Cr\u00e9er le mod\u00e8le PCA\n",
    "# pca = PCA(\n",
    "#     k=K_COMPONENTS,\n",
    "#     inputCol=\"features_vector\",\n",
    "#     outputCol=\"pca_features\"\n",
    "# )\n",
    "\n",
    "# # Entra\u00eener le mod\u00e8le PCA\n",
    "# pca_model = pca.fit(df_for_pca)\n",
    "\n",
    "# # Appliquer la transformation PCA\n",
    "# df_pca = pca_model.transform(df_for_pca)\n",
    "\n",
    "# print(f\"\u2705 PCA appliqu\u00e9e (r\u00e9duction de 1280 \u00e0 {K_COMPONENTS} dimensions)\")\n",
    "# df_pca.select(\"label\", \"pca_features\").show(5, truncate=60)\n",
    "\n",
    "print(f\"\u26a0\ufe0f Configuration: k={K_COMPONENTS} composantes\")\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter une fois les vecteurs de features pr\u00e9par\u00e9s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Analyse de la variance expliqu\u00e9e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance expliqu\u00e9e par chaque composante\n",
    "# explained_variance = pca_model.explainedVariance\n",
    "\n",
    "# print(f\"\ud83d\udcca Variance expliqu\u00e9e:\")\n",
    "# print(f\"   Total: {sum(explained_variance):.4f}\")\n",
    "# print(f\"   Par composante (top 10):\")\n",
    "# for i, var in enumerate(explained_variance[:10]):\n",
    "#     print(f\"   PC{i+1}: {var:.6f}\")\n",
    "\n",
    "# # Variance cumul\u00e9e\n",
    "# import matplotlib.pyplot as plt\n",
    "# cumsum_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(cumsum_variance) + 1), cumsum_variance)\n",
    "# plt.xlabel('Nombre de composantes')\n",
    "# plt.ylabel('Variance cumul\u00e9e expliqu\u00e9e')\n",
    "# plt.title('Variance expliqu\u00e9e par les composantes principales')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter une fois la PCA appliqu\u00e9e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Sauvegarde des r\u00e9sultats PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S\u00e9lectionner les colonnes pertinentes\n",
    "# df_final = df_pca.select(\"path\", \"label\", \"pca_features\")\n",
    "\n",
    "# # Sauvegarder en Parquet\n",
    "# pca_output_path = str(PCA_DIR / \"pca_results\")\n",
    "# df_final.write.mode(\"overwrite\").parquet(pca_output_path)\n",
    "\n",
    "# print(f\"\u2705 R\u00e9sultats PCA sauvegard\u00e9s: {pca_output_path}\")\n",
    "\n",
    "# # Sauvegarder aussi en CSV pour inspection\n",
    "# # Note: Le CSV sera partitionn\u00e9 en plusieurs fichiers\n",
    "# csv_output_path = str(PCA_DIR / \"pca_results_csv\")\n",
    "# df_final.write.mode(\"overwrite\").option(\"header\", \"true\").csv(csv_output_path)\n",
    "\n",
    "# print(f\"\u2705 R\u00e9sultats PCA sauvegard\u00e9s en CSV: {csv_output_path}\")\n",
    "\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter une fois la PCA appliqu\u00e9e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Tests et Validation\n",
    "\n",
    "### 7.1 V\u00e9rification des dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V\u00e9rifier les dimensions \u00e0 chaque \u00e9tape\n",
    "# print(\"\ud83d\udcca Dimensions:\")\n",
    "# print(f\"   Images originales: {df_images.count()} images\")\n",
    "# print(f\"   Features extraites: {df_features.count()} images x 1280 features\")\n",
    "# print(f\"   Apr\u00e8s PCA: {df_pca.count()} images x {K_COMPONENTS} features\")\n",
    "\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter pour v\u00e9rifier le pipeline complet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Test sur un \u00e9chantillon\n",
    "\n",
    "Tester le pipeline complet sur un petit \u00e9chantillon pour valider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prendre un \u00e9chantillon de 100 images\n",
    "# sample_images = df_images.limit(100)\n",
    "\n",
    "# # Appliquer tout le pipeline\n",
    "# sample_with_labels = sample_images.withColumn(\n",
    "#     \"label\",\n",
    "#     element_at(split(col(\"path\"), \"/\"), -2)\n",
    "# )\n",
    "\n",
    "# sample_features = sample_with_labels.withColumn(\n",
    "#     \"features\",\n",
    "#     extract_features_udf(col(\"content\"))\n",
    "# ).filter(col(\"features\").isNotNull())\n",
    "\n",
    "# sample_vectors = sample_features.withColumn(\n",
    "#     \"features_vector\",\n",
    "#     array_to_vector(col(\"features\"))\n",
    "# )\n",
    "\n",
    "# sample_pca = pca_model.transform(sample_vectors)\n",
    "\n",
    "# print(f\"\u2705 Test sur \u00e9chantillon: {sample_pca.count()} images trait\u00e9es\")\n",
    "# sample_pca.select(\"label\", \"pca_features\").show(10, truncate=60)\n",
    "\n",
    "print(\"\u26a0\ufe0f \u00c0 ex\u00e9cuter pour tester le pipeline sur un \u00e9chantillon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Nettoyage et Arr\u00eat\n",
    "\n",
    "### 8.1 Lib\u00e9rer les ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpersist les DataFrames mis en cache (si utilis\u00e9 .cache())\n",
    "# df_features.unpersist()\n",
    "# df_pca.unpersist()\n",
    "\n",
    "# D\u00e9truire la variable broadcast\n",
    "broadcast_weights.unpersist()\n",
    "\n",
    "print(\"\u2705 Ressources lib\u00e9r\u00e9es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Arr\u00eat de la SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arr\u00eater la SparkSession\n",
    "# spark.stop()\n",
    "# print(\"\u2705 SparkSession arr\u00eat\u00e9e\")\n",
    "\n",
    "print(\"\u26a0\ufe0f D\u00e9commenter pour arr\u00eater Spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \ud83d\udcdd Notes pour la migration vers AWS EMR\n",
    "\n",
    "### Changements \u00e0 apporter:\n",
    "\n",
    "1. **Chemins S3**\n",
    "   ```python\n",
    "   # Local\n",
    "   image_path = \"file:///path/to/images/*/*.jpg\"\n",
    "   \n",
    "   # AWS EMR\n",
    "   image_path = \"s3://mon-bucket-fruits/data/raw/Training/*/*.jpg\"\n",
    "   ```\n",
    "\n",
    "2. **Configuration Spark**\n",
    "   - Sur EMR JupyterHub, la SparkSession est d\u00e9j\u00e0 cr\u00e9\u00e9e\n",
    "   - Pas besoin de `.master(\"local[*]\")`\n",
    "   - Le SparkContext est accessible via `spark.sparkContext`\n",
    "\n",
    "3. **Installation de packages**\n",
    "   - TensorFlow doit \u00eatre install\u00e9 via bootstrap actions ou dans le notebook\n",
    "   - Sur EMR 7.10.0: TensorFlow 2.16.1 peut \u00eatre pr\u00e9-install\u00e9\n",
    "\n",
    "4. **Sauvegarde des r\u00e9sultats**\n",
    "   ```python\n",
    "   # Sauvegarder directement sur S3\n",
    "   df_pca.write.mode(\"overwrite\").csv(\"s3://mon-bucket-fruits/data/pca/\")\n",
    "   ```\n",
    "\n",
    "5. **Monitoring**\n",
    "   - Utiliser Spark UI pour suivre l'ex\u00e9cution\n",
    "   - Accessible via le tunnel SSH et FoxyProxy\n",
    "\n",
    "### Checklist avant migration:\n",
    "\n",
    "- [ ] Code valid\u00e9 en local sur un subset\n",
    "- [ ] Broadcast des poids fonctionne correctement\n",
    "- [ ] PCA appliqu\u00e9e et valid\u00e9e\n",
    "- [ ] Chemins adapt\u00e9s pour S3\n",
    "- [ ] Dataset upload\u00e9 sur S3\n",
    "- [ ] Cluster EMR cr\u00e9\u00e9 et configur\u00e9\n",
    "- [ ] Tunnel SSH et FoxyProxy configur\u00e9s\n",
    "- [ ] Acc\u00e8s JupyterHub v\u00e9rifi\u00e9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}