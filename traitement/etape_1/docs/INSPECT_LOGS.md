# üìã Guide d'inspection des logs EMR

Ce guide vous aide √† t√©l√©charger et analyser les logs de votre job PySpark sur EMR.

## üìÅ Fichiers de r√©f√©rence

Le dossier `traitement/etape_1/` contient les identifiants n√©cessaires :

- `cluster_id.txt` - ID du cluster EMR
- `step_id.txt` - ID du job soumis
- `master_dns.txt` - DNS du n≈ìud master (pour SSH)

## üîç Inspection rapide

### 1. Charger les identifiants

```bash
cd traitement/etape_1

CLUSTER_ID=$(cat cluster_id.txt)
STEP_ID=$(cat step_id.txt)
MASTER_DNS=$(cat master_dns.txt)

echo "Cluster: ${CLUSTER_ID}"
echo "Step: ${STEP_ID}"
echo "Master: ${MASTER_DNS}"
```

### 2. V√©rifier l'√©tat actuel du job

```bash
aws emr describe-step \
    --cluster-id ${CLUSTER_ID} \
    --step-id ${STEP_ID} \
    --region eu-west-1 \
    --query 'Step.Status'
```

## üì• T√©l√©charger les logs

### Logs disponibles

```bash
# Lister tous les logs disponibles pour ce step
aws s3 ls s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/ \
    --region eu-west-1 \
    --human-readable
```

### T√©l√©charger dans le dossier logs/

```bash
# Cr√©er le dossier logs
mkdir -p logs

# T√©l√©charger stderr (logs du driver Spark - le plus important)
aws s3 cp s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/stderr.gz \
    logs/ --region eu-west-1

# T√©l√©charger controller (infos sur l'ex√©cution du job)
aws s3 cp s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/controller.gz \
    logs/ --region eu-west-1

# T√©l√©charger stdout (si disponible)
aws s3 cp s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/stdout.gz \
    logs/ --region eu-west-1 2>/dev/null || echo "Pas de stdout"

# D√©compresser tous les fichiers
gunzip logs/*.gz 2>/dev/null || true
```

## üîé Analyser les logs

### Stderr (logs principaux du script)

```bash
# Voir tout le fichier
cat logs/stderr

# Voir les 100 derni√®res lignes
tail -100 logs/stderr

# Voir les 50 premi√®res lignes
head -50 logs/stderr

# Chercher les erreurs
grep -i "error\|exception\|failed\|traceback" logs/stderr

# Chercher les √©tapes de votre script
grep "üçé\|üìÇ\|‚úÖ\|‚ùå\|üìä" logs/stderr

# Chercher les infos sur les donn√©es
grep -i "fichiers\|images\|count\|training\|test" logs/stderr

# Voir les warnings
grep -i "warning\|warn" logs/stderr
```

### Controller (infos sur le job)

```bash
# Voir le fichier controller
cat logs/controller

# Voir juste le r√©sum√©
head -20 logs/controller
```

### Stdout (si disponible)

```bash
cat logs/stdout 2>/dev/null || echo "Pas de stdout disponible"
```

## üöÄ Inspection en temps r√©el (sans t√©l√©charger)

### Voir directement le stderr (50 derni√®res lignes)

```bash
aws s3 cp s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/stderr.gz - \
    --region eu-west-1 | gunzip | tail -50
```

### Voir tout le stderr

```bash
aws s3 cp s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/stderr.gz - \
    --region eu-west-1 | gunzip | less
```

### Surveiller l'ajout de nouveaux logs

```bash
# V√©rifier la taille du fichier stderr (augmente pendant l'ex√©cution)
watch -n 5 "aws s3 ls s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/ --region eu-west-1 --human-readable"
```

## üìä Logs du cluster (niveau sup√©rieur)

### Logs globaux du cluster

```bash
# Lister tous les logs du cluster
aws s3 ls s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/ \
    --recursive --region eu-west-1 --human-readable

# Logs des nodes (master, core)
aws s3 ls s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/node/ \
    --recursive --region eu-west-1
```

### Logs de bootstrap

```bash
# Voir si le bootstrap s'est bien ex√©cut√©
aws s3 ls s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/node/*/bootstrap-actions/ \
    --recursive --region eu-west-1
```

## üêõ D√©bogage avanc√©

### Connexion SSH au master node

```bash
# Connexion SSH (n√©cessite la cl√© SSH configur√©e)
ssh -i ~/.ssh/emr-p11-fruits-key-codespace.pem hadoop@${MASTER_DNS}

# Une fois connect√©, voir les logs YARN
yarn logs -applicationId <application_id>

# Voir les logs Spark
ls -la /var/log/spark/
```

### Trouver l'Application ID Spark

```bash
# Dans les logs stderr, chercher
grep "application_" logs/stderr | head -1
```

### Logs YARN via S3

```bash
# Les logs YARN sont aussi copi√©s sur S3 apr√®s la fin du job
aws s3 ls s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/containers/ \
    --recursive --region eu-west-1
```

## üìà M√©triques et monitoring

### Voir les m√©triques du step

```bash
aws emr describe-step \
    --cluster-id ${CLUSTER_ID} \
    --step-id ${STEP_ID} \
    --region eu-west-1 \
    --query 'Step.Status.Timeline'
```

### Voir l'historique de tous les steps

```bash
aws emr list-steps \
    --cluster-id ${CLUSTER_ID} \
    --region eu-west-1 \
    --query 'Steps[*].[Id,Name,Status.State,Status.Timeline.StartDateTime,Status.Timeline.EndDateTime]' \
    --output table
```

## ‚ùì Messages d'erreur courants

### "File does not exist"
- Le script Python n'a pas √©t√© trouv√© sur S3
- V√©rifier : `aws s3 ls s3://oc-p11-fruits-david-scanu/read_fruits_data/scripts/ --region eu-west-1`

### "Permission denied"
- Probl√®me de r√¥les IAM
- V√©rifier les r√¥les EMR dans la config

### "No space left on device"
- Disque EBS plein
- Augmenter `EBS_VOLUME_SIZE` dans `config/config.sh`

### Job bloqu√© longtemps
- Regarder la taille du stderr qui augmente
- V√©rifier les logs YARN pour voir l'activit√© des executors

## üîÑ Script automatis√©

### T√©l√©charger et afficher en une commande

```bash
# Script all-in-one
./scripts/download_and_inspect_logs.sh
```

### Cr√©er ce script

```bash
cat > scripts/download_and_inspect_logs.sh << 'EOF'
#!/bin/bash
set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "${SCRIPT_DIR}/.."

CLUSTER_ID=$(cat cluster_id.txt)
STEP_ID=$(cat step_id.txt)

echo "=================================================="
echo "üìã T√©l√©chargement des logs"
echo "=================================================="
echo "Cluster: ${CLUSTER_ID}"
echo "Step: ${STEP_ID}"
echo ""

mkdir -p logs
aws s3 sync s3://oc-p11-fruits-david-scanu/read_fruits_data/logs/emr/${CLUSTER_ID}/steps/${STEP_ID}/ \
    logs/ --region eu-west-1

gunzip logs/*.gz 2>/dev/null || true

echo "=================================================="
echo "üìä STDERR (50 derni√®res lignes)"
echo "=================================================="
tail -50 logs/stderr

echo ""
echo "=================================================="
echo "‚ùå ERREURS D√âTECT√âES"
echo "=================================================="
grep -i "error\|exception\|failed" logs/stderr || echo "Aucune erreur trouv√©e"

echo ""
echo "üìÅ Logs sauvegard√©s dans: logs/"
EOF

chmod +x scripts/download_and_inspect_logs.sh
```

## üìö Ressources

- [AWS EMR - Logs de debug](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-manage-debugging.html)
- [Spark - Configuration des logs](https://spark.apache.org/docs/latest/configuration.html#configuring-logging)
- [YARN - Application logs](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YarnCommands.html#logs)

## üí° Conseils

1. **Toujours v√©rifier stderr en premier** - c'est l√† que sont les prints de votre script
2. **Chercher les emojis** de votre script pour suivre la progression
3. **Regarder les timestamps** pour identifier les √©tapes lentes
4. **Sauvegarder les logs** avant de terminer le cluster
5. **Comparer avec les logs locaux** si vous avez test√© en local

---

**Derni√®re mise √† jour**: 2025-11-18