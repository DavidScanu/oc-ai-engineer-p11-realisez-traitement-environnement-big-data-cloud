# Ã‰tape 1 : Lecture et indexation du dataset Fruits-360 avec PySpark sur AWS EMR

## ğŸ“‹ Objectifs

Cette premiÃ¨re Ã©tape valide la mise en place de l'infrastructure Big Data sur AWS :

1. **Lire les donnÃ©es depuis S3** : Charger le dataset Fruits-360 (images JPG)
2. **CrÃ©er un DataFrame PySpark** : GÃ©nÃ©rer un index avec mÃ©tadonnÃ©es (nom fichier, chemin S3, label, etc.)
3. **Sauvegarder en CSV sur S3** : Ã‰crire les rÃ©sultats traitÃ©s
4. **Valider l'environnement** :
   - Installation correcte des packages Python via bootstrap action
   - Lecture/Ã©criture S3 fonctionnelle
   - ExÃ©cution PySpark distribuÃ©e sur EMR

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AWS Cloud (eu-west-1)               â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              â”‚         â”‚     EMR Cluster             â”‚  â”‚
â”‚  â”‚   S3 Bucket  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤                             â”‚  â”‚
â”‚  â”‚              â”‚         â”‚  Master (m5.xlarge)         â”‚  â”‚
â”‚  â”‚  - Input:    â”‚         â”‚  Core x2 (m5.xlarge)        â”‚  â”‚
â”‚  â”‚    Images    â”‚         â”‚                             â”‚  â”‚
â”‚  â”‚  - Scripts   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Spark 3.x + PySpark        â”‚  â”‚
â”‚  â”‚  - Output:   â”‚         â”‚  + Bootstrap (Python deps)  â”‚  â”‚
â”‚  â”‚    CSV       â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Structure du projet

```
traitement/etape_1/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.sh              # Configuration centralisÃ©e (S3, EMR, rÃ©seau)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ install_dependencies.sh   # Bootstrap action (installation packages)
â”‚   â”œâ”€â”€ read_fruits_data.py       # Script PySpark principal
â”‚   â”œâ”€â”€ create_cluster.sh         # CrÃ©ation du cluster EMR
â”‚   â”œâ”€â”€ monitor_cluster.sh        # Surveillance de l'Ã©tat du cluster
â”‚   â”œâ”€â”€ upload_scripts.sh         # Upload des scripts sur S3
â”‚   â”œâ”€â”€ verify_setup.sh           # VÃ©rification de la configuration
â”‚   â”œâ”€â”€ submit_job.sh             # Soumission du job PySpark (step)
â”‚   â”œâ”€â”€ terminate_cluster.sh      # Terminaison du cluster
â”‚   â””â”€â”€ cleanup.sh                # Nettoyage complet des ressources
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ (documentation supplÃ©mentaire)
â”‚
â”œâ”€â”€ cluster_id.txt    # GÃ©nÃ©rÃ© automatiquement (ID du cluster)
â”œâ”€â”€ step_id.txt       # GÃ©nÃ©rÃ© automatiquement (ID du job)
â””â”€â”€ README.md         # Ce fichier
```

## âš™ï¸ Configuration

### 1. Ã‰diter la configuration

Ouvrir [config/config.sh](config/config.sh) et adapter les valeurs suivantes :

```bash
# Ã€ MODIFIER selon votre environnement AWS
export S3_BUCKET="votre-bucket-s3"
export EC2_KEY_NAME="votre-cle-ssh"
export MASTER_SECURITY_GROUP="sg-xxxxxxxxx"
export SLAVE_SECURITY_GROUP="sg-xxxxxxxxx"
export EC2_SUBNET="subnet-xxxxxxxxx"

# RÃ´les IAM (ARNs complets)
export IAM_SERVICE_ROLE="arn:aws:iam::ACCOUNT_ID:role/EMR_DefaultRole"
export IAM_INSTANCE_PROFILE="EMR_EC2_DefaultRole"
export IAM_AUTOSCALING_ROLE="arn:aws:iam::ACCOUNT_ID:role/EMR_AutoScaling_DefaultRole"
```

**Important** :
- La rÃ©gion par dÃ©faut est `eu-west-1` (conformitÃ© GDPR)
- Pour crÃ©er les rÃ´les IAM par dÃ©faut : `aws emr create-default-roles`

### 2. PrÃ©parer les donnÃ©es

Uploader le dataset Fruits-360 sur S3 :

```bash
# TÃ©lÃ©charger le dataset (si nÃ©cessaire)
wget https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/Data_Scientist_P8/fruits.zip
unzip fruits.zip

# Uploader vers S3
aws s3 sync fruits/ s3://votre-bucket/data/fruits-360/ --region eu-west-1
```

Structure attendue sur S3 :
```
s3://votre-bucket/data/fruits-360/
â”œâ”€â”€ Training/
â”‚   â”œâ”€â”€ Apple_Braeburn/
â”‚   â”‚   â”œâ”€â”€ image_001_100.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Banana/
â”‚   â””â”€â”€ ...
â””â”€â”€ Test/
    â”œâ”€â”€ Apple_Braeburn/
    â””â”€â”€ ...
```

## ğŸš€ Utilisation

### Workflow complet

#### 1ï¸âƒ£ VÃ©rifier la configuration

```bash
cd traitement/etape_1
chmod +x scripts/*.sh
./scripts/verify_setup.sh
```

Ce script vÃ©rifie :
- âœ… RÃ©gion AWS (Europe pour GDPR)
- âœ… Credentials AWS configurÃ©s
- âœ… Bucket S3 existe
- âœ… DonnÃ©es d'entrÃ©e prÃ©sentes
- âœ… ClÃ© SSH existe
- âœ… RÃ´les IAM configurÃ©s

#### 2ï¸âƒ£ Uploader les scripts sur S3

```bash
./scripts/upload_scripts.sh
```

Upload :
- `install_dependencies.sh` â†’ `s3://bucket/scripts/`
- `read_fruits_data.py` â†’ `s3://bucket/scripts/`

#### 3ï¸âƒ£ CrÃ©er le cluster EMR

```bash
./scripts/create_cluster.sh
```

Cette commande :
- CrÃ©e un cluster EMR 7.11.0 avec Spark
- Configure 1 Master + 2 Core (m5.xlarge)
- ExÃ©cute le bootstrap action (installation Python)
- Active l'auto-terminaison aprÃ¨s 4h d'inactivitÃ©
- Sauvegarde le Cluster ID dans `cluster_id.txt`

**CoÃ»t estimÃ©** : ~0.50â‚¬/heure

#### 4ï¸âƒ£ Surveiller le dÃ©marrage du cluster

```bash
./scripts/monitor_cluster.sh
```

Affiche l'Ã©tat en temps rÃ©el :
- ğŸŸ¡ STARTING â†’ DÃ©marrage EC2
- ğŸŸ¡ BOOTSTRAPPING â†’ Installation dÃ©pendances Python
- ğŸŸ¢ RUNNING â†’ Configuration Spark
- âœ… WAITING â†’ PrÃªt Ã  recevoir des jobs

**DurÃ©e** : 10-15 minutes

#### 5ï¸âƒ£ Soumettre le job PySpark

Une fois le cluster en Ã©tat `WAITING` :

```bash
./scripts/submit_job.sh
```

Cette commande :
- VÃ©rifie que le cluster est prÃªt
- Soumet un step PySpark avec `spark-submit`
- Sauvegarde le Step ID dans `step_id.txt`

#### 6ï¸âƒ£ Surveiller l'exÃ©cution du job

```bash
# Surveillance continue
watch -n 10 'aws emr describe-step --cluster-id $(cat cluster_id.txt) --step-id $(cat step_id.txt) --region eu-west-1 --query "Step.Status.State" --output text'

# VÃ©rification ponctuelle
aws emr describe-step --cluster-id $(cat cluster_id.txt) --step-id $(cat step_id.txt) --region eu-west-1
```

**DurÃ©e** : 2-5 minutes

#### 7ï¸âƒ£ RÃ©cupÃ©rer les rÃ©sultats

```bash
# Lister les rÃ©sultats
aws s3 ls s3://votre-bucket/output/etape_1/ --recursive --region eu-west-1

# TÃ©lÃ©charger les CSV
aws s3 cp s3://votre-bucket/output/etape_1/ ./results/ --recursive --region eu-west-1
```

Fichiers gÃ©nÃ©rÃ©s :
- `metadata_YYYYMMDD_HHMMSS/` : DataFrame avec toutes les images (chemin S3, label, taille, etc.)
- `stats_YYYYMMDD_HHMMSS/` : Statistiques par classe (Training/Test)

#### 8ï¸âƒ£ Terminer le cluster

```bash
./scripts/terminate_cluster.sh
```

**âš ï¸ IMPORTANT** : Toujours terminer le cluster pour Ã©viter des coÃ»ts inutiles !

### ğŸ§¹ Nettoyage complet

Pour nettoyer toutes les ressources (cluster + donnÃ©es + logs) :

```bash
./scripts/cleanup.sh
```

Ce script interactif propose de supprimer :
- Le cluster EMR (si actif)
- Les donnÃ©es de sortie sur S3
- Les logs EMR sur S3
- Les fichiers de tracking locaux (`cluster_id.txt`, etc.)

## ğŸ“Š Script PySpark : `read_fruits_data.py`

### Fonctionnement

1. **Lecture des images** : Utilise `binaryFile` pour lire tous les `.jpg` rÃ©cursivement depuis S3
2. **Extraction des mÃ©tadonnÃ©es** : Regex pour extraire label, split (Training/Test), nom de fichier
3. **Calcul de statistiques** : Comptage par classe et par split
4. **Sauvegarde en CSV** : Coalesce + write en mode overwrite

### SchÃ©ma du DataFrame de sortie

| Colonne            | Type      | Description                                  |
|--------------------|-----------|----------------------------------------------|
| `s3_path`          | String    | Chemin complet S3 de l'image                 |
| `label`            | String    | Nom de la classe (ex: "Apple_Braeburn")      |
| `filename`         | String    | Nom du fichier (ex: "image_001_100.jpg")     |
| `split`            | String    | "Training" ou "Test"                         |
| `modification_time`| Timestamp | Date de derniÃ¨re modification                |
| `file_size_bytes`  | Long      | Taille du fichier en octets                  |

### Exemple de sortie

```
+------------------------------------------------+---------------+--------------------+--------+-------------------+----------------+
|s3_path                                         |label          |filename            |split   |modification_time  |file_size_bytes |
+------------------------------------------------+---------------+--------------------+--------+-------------------+----------------+
|s3://.../Training/Apple_Braeburn/image_001_100.jpg|Apple_Braeburn|image_001_100.jpg   |Training|2025-01-15 10:23:45|5432            |
|s3://.../Training/Apple_Braeburn/image_002_100.jpg|Apple_Braeburn|image_002_100.jpg   |Training|2025-01-15 10:23:45|5621            |
|s3://.../Test/Banana/r_image_042_100.jpg        |Banana         |r_image_042_100.jpg |Test    |2025-01-15 10:24:12|4892            |
+------------------------------------------------+---------------+--------------------+--------+-------------------+----------------+
```

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : Cluster ne dÃ©marre pas (TERMINATED_WITH_ERRORS)

**Causes frÃ©quentes** :
1. Bootstrap action Ã©choue â†’ VÃ©rifier les logs dans `s3://bucket/logs/emr/`
2. RÃ´les IAM incorrects â†’ VÃ©rifier `config.sh` et les permissions
3. Subnet/Security Groups incompatibles â†’ VÃ©rifier la configuration rÃ©seau

**Solution** :
```bash
# Consulter les logs dÃ©taillÃ©s
aws emr describe-cluster --cluster-id $(cat cluster_id.txt) --region eu-west-1

# Logs du bootstrap
aws s3 ls s3://bucket/logs/emr/ --recursive | grep bootstrap
```

### ProblÃ¨me : Job PySpark Ã©choue

**VÃ©rifier les logs** :
```bash
# Logs du step
aws s3 ls s3://bucket/logs/emr/containers/ --recursive | grep $(cat step_id.txt)

# TÃ©lÃ©charger les logs
aws s3 cp s3://bucket/logs/emr/containers/ ./logs/ --recursive
```

**Erreurs courantes** :
- `FileNotFoundError` : VÃ©rifier que les donnÃ©es sont bien sur S3
- `ImportError` : Package Python manquant â†’ VÃ©rifier `install_dependencies.sh`
- `PermissionDenied` : ProblÃ¨me IAM â†’ VÃ©rifier le rÃ´le `EMR_EC2_DefaultRole`

### ProblÃ¨me : CoÃ»ts Ã©levÃ©s

**VÃ©rifier les instances en cours** :
```bash
aws ec2 describe-instances --region eu-west-1 \
  --filters "Name=instance-state-name,Values=running" \
  --query 'Reservations[*].Instances[*].[InstanceId,InstanceType,Tags[?Key==`Name`].Value|[0]]' \
  --output table
```

**Terminer toutes les instances EMR** :
```bash
# Lister tous les clusters actifs
aws emr list-clusters --active --region eu-west-1

# Terminer un cluster spÃ©cifique
aws emr terminate-clusters --cluster-ids j-XXXXXXXXXXXXX --region eu-west-1
```

## ğŸ“ˆ Prochaines Ã©tapes

AprÃ¨s validation de cette Ã©tape :

1. **Ã‰tape 2** : Extraction de features avec TensorFlow (MobileNetV2)
2. **Ã‰tape 3** : Broadcast des poids du modÃ¨le TensorFlow
3. **Ã‰tape 4** : PCA (rÃ©duction de dimensionnalitÃ©) en PySpark

## ğŸ“š Ressources

- [Documentation AWS EMR](https://docs.aws.amazon.com/emr/)
- [Guide PySpark](https://spark.apache.org/docs/latest/api/python/)
- [Dataset Fruits-360](https://www.kaggle.com/datasets/moltean/fruits)
- [AWS EMR Getting Started](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-gs.html)

## ğŸ”’ ConformitÃ© GDPR

- âœ… RÃ©gion AWS Europe (`eu-west-1`)
- âœ… Stockage S3 en Europe
- âœ… Instances EMR en Europe
- âœ… Pas de transfert de donnÃ©es hors UE

## ğŸ“ Notes importantes

1. **Auto-terminaison** : Le cluster s'arrÃªte automatiquement aprÃ¨s 4h d'inactivitÃ©
2. **CoÃ»ts** : ~0.50â‚¬/heure pour la configuration actuelle (1 Master + 2 Core m5.xlarge)
3. **SÃ©curitÃ©** : Ne jamais commiter de credentials AWS dans Git
4. **Logs** : Toujours activer les logs EMR pour faciliter le debugging

## â“ Support

En cas de problÃ¨me, vÃ©rifier dans l'ordre :

1. `./scripts/verify_setup.sh` â†’ Configuration correcte ?
2. Logs EMR â†’ `s3://bucket/logs/emr/`
3. Console AWS EMR â†’ Ã‰tat dÃ©taillÃ© du cluster
4. Documentation AWS â†’ Messages d'erreur spÃ©cifiques
