{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R√©sultats - Mode MINI (300 images)\n",
    "\n",
    "**Date d'ex√©cution**: 21 novembre 2025  \n",
    "**Mode**: MINI (300 images de pommes)  \n",
    "**Pipeline**: Feature Extraction (MobileNetV2) + PCA (50 composantes)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Table des mati√®res\n",
    "\n",
    "1. [Configuration et chargement des donn√©es](#1-configuration-et-chargement)\n",
    "2. [M√©tadonn√©es](#2-m√©tadonn√©es)\n",
    "3. [Features brutes (1280D)](#3-features-brutes)\n",
    "4. [Features PCA (50D)](#4-features-pca)\n",
    "5. [Informations du mod√®le PCA](#5-mod√®le-pca)\n",
    "6. [Visualisations](#6-visualisations)\n",
    "7. [Conclusions](#7-conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Chemins des donn√©es\n",
    "BASE_DIR = Path('.')\n",
    "METADATA_DIR = BASE_DIR / 'metadata'\n",
    "FEATURES_DIR = BASE_DIR / 'features' / 'csv'\n",
    "PCA_DIR = BASE_DIR / 'pca' / 'csv'\n",
    "MODEL_INFO_DIR = BASE_DIR / 'model_info'\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis\")\n",
    "print(f\"üìÇ R√©pertoire de travail: {BASE_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. M√©tadonn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les m√©tadonn√©es\n",
    "metadata_files = list(METADATA_DIR.glob('**/part-*.csv'))\n",
    "print(f\"üìÑ Fichiers de m√©tadonn√©es trouv√©s: {len(metadata_files)}\")\n",
    "\n",
    "if metadata_files:\n",
    "    df_metadata = pd.concat([pd.read_csv(f) for f in metadata_files], ignore_index=True)\n",
    "    print(f\"‚úÖ M√©tadonn√©es charg√©es: {len(df_metadata)} images\")\n",
    "else:\n",
    "    print(\"‚ùå Aucun fichier de m√©tadonn√©es trouv√©\")\n",
    "    df_metadata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_metadata is not None:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä STATISTIQUES DES M√âTADONN√âES\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nüñºÔ∏è  Nombre total d'images: {len(df_metadata):,}\")\n",
    "    print(f\"üè∑Ô∏è  Nombre de classes: {df_metadata['label'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nüì¶ Colonnes disponibles:\")\n",
    "    print(df_metadata.columns.tolist())\n",
    "    \n",
    "    print(\"\\nüëÅÔ∏è  Aper√ßu des donn√©es:\")\n",
    "    display(df_metadata.head(10))\n",
    "    \n",
    "    print(\"\\nüìä Distribution des classes:\")\n",
    "    class_counts = df_metadata['label'].value_counts()\n",
    "    display(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_metadata is not None:\n",
    "    # Visualisation de la distribution des classes\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    class_counts = df_metadata['label'].value_counts()\n",
    "    class_counts.plot(kind='bar', ax=ax, color='skyblue', edgecolor='black')\n",
    "    ax.set_title('Distribution des images par classe', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Classe', fontsize=12)\n",
    "    ax.set_ylabel('Nombre d\\'images', fontsize=12)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Statistiques:\")\n",
    "    print(f\"   ‚Ä¢ Classe la plus repr√©sent√©e: {class_counts.idxmax()} ({class_counts.max()} images)\")\n",
    "    print(f\"   ‚Ä¢ Classe la moins repr√©sent√©e: {class_counts.idxmin()} ({class_counts.min()} images)\")\n",
    "    print(f\"   ‚Ä¢ Moyenne par classe: {class_counts.mean():.1f} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Features brutes (1280D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les features brutes\n",
    "features_files = list(FEATURES_DIR.glob('**/part-*.csv'))\n",
    "print(f\"üìÑ Fichiers de features trouv√©s: {len(features_files)}\")\n",
    "\n",
    "if features_files:\n",
    "    df_features = pd.concat([pd.read_csv(f) for f in features_files], ignore_index=True)\n",
    "    print(f\"‚úÖ Features charg√©es: {len(df_features)} images\")\n",
    "    \n",
    "    # Convertir la colonne features_string en array\n",
    "    df_features['features_array'] = df_features['features_string'].apply(\n",
    "        lambda x: np.array([float(v) for v in x.split(',')]) if pd.notna(x) else None\n",
    "    )\n",
    "    print(f\"‚úÖ Conversion en arrays numpy r√©ussie\")\n",
    "else:\n",
    "    print(\"‚ùå Aucun fichier de features trouv√©\")\n",
    "    df_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_features is not None and 'features_array' in df_features.columns:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üé® ANALYSE DES FEATURES BRUTES (MobileNetV2 - 1280D)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Afficher quelques √©chantillons\n",
    "    print(\"\\nüëÅÔ∏è  Aper√ßu des donn√©es (5 premi√®res lignes):\")\n",
    "    display(df_features[['path', 'label']].head())\n",
    "    \n",
    "    # Cr√©er une matrice de features\n",
    "    features_matrix = np.vstack(df_features['features_array'].values)\n",
    "    print(f\"\\nüìê Shape de la matrice: {features_matrix.shape}\")\n",
    "    print(f\"   ‚Ä¢ Nombre d'images: {features_matrix.shape[0]}\")\n",
    "    print(f\"   ‚Ä¢ Dimensions par image: {features_matrix.shape[1]}\")\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    print(f\"\\nüìä Statistiques des features:\")\n",
    "    print(f\"   ‚Ä¢ Min: {features_matrix.min():.6f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {features_matrix.max():.6f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {features_matrix.mean():.6f}\")\n",
    "    print(f\"   ‚Ä¢ Std: {features_matrix.std():.6f}\")\n",
    "    print(f\"   ‚Ä¢ M√©diane: {np.median(features_matrix):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_features is not None and 'features_array' in df_features.columns:\n",
    "    # Visualisation: Heatmap des premi√®res features\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Heatmap des 50 premi√®res dimensions pour 20 images\n",
    "    sample_features = features_matrix[:20, :50]\n",
    "    sns.heatmap(sample_features, cmap='viridis', ax=ax1, cbar_kws={'label': 'Valeur'})\n",
    "    ax1.set_title('Heatmap des features (20 images √ó 50 premi√®res dimensions)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Dimension de feature')\n",
    "    ax1.set_ylabel('Image')\n",
    "    \n",
    "    # Distribution des valeurs de features\n",
    "    ax2.hist(features_matrix.flatten(), bins=100, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    ax2.set_title('Distribution des valeurs de features', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Valeur')\n",
    "    ax2.set_ylabel('Fr√©quence')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Features PCA (50D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les features PCA\n",
    "pca_files = list(PCA_DIR.glob('**/part-*.csv'))\n",
    "print(f\"üìÑ Fichiers PCA trouv√©s: {len(pca_files)}\")\n",
    "\n",
    "if pca_files:\n",
    "    df_pca = pd.concat([pd.read_csv(f) for f in pca_files], ignore_index=True)\n",
    "    print(f\"‚úÖ Features PCA charg√©es: {len(df_pca)} images\")\n",
    "    \n",
    "    # Convertir la colonne pca_features_string en array\n",
    "    df_pca['pca_array'] = df_pca['pca_features_string'].apply(\n",
    "        lambda x: np.array([float(v) for v in x.split(',')]) if pd.notna(x) else None\n",
    "    )\n",
    "    print(f\"‚úÖ Conversion en arrays numpy r√©ussie\")\n",
    "else:\n",
    "    print(\"‚ùå Aucun fichier PCA trouv√©\")\n",
    "    df_pca = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_pca is not None and 'pca_array' in df_pca.columns:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä ANALYSE DES FEATURES PCA (50D)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Afficher quelques √©chantillons\n",
    "    print(\"\\nüëÅÔ∏è  Aper√ßu des donn√©es (5 premi√®res lignes):\")\n",
    "    display(df_pca[['path', 'label']].head())\n",
    "    \n",
    "    # Cr√©er une matrice PCA\n",
    "    pca_matrix = np.vstack(df_pca['pca_array'].values)\n",
    "    print(f\"\\nüìê Shape de la matrice PCA: {pca_matrix.shape}\")\n",
    "    print(f\"   ‚Ä¢ Nombre d'images: {pca_matrix.shape[0]}\")\n",
    "    print(f\"   ‚Ä¢ Dimensions par image: {pca_matrix.shape[1]}\")\n",
    "    print(f\"   ‚Ä¢ R√©duction: 1280 ‚Üí {pca_matrix.shape[1]} ({(1 - pca_matrix.shape[1]/1280)*100:.1f}% compression)\")\n",
    "    \n",
    "    # Statistiques descriptives\n",
    "    print(f\"\\nüìä Statistiques des features PCA:\")\n",
    "    print(f\"   ‚Ä¢ Min: {pca_matrix.min():.6f}\")\n",
    "    print(f\"   ‚Ä¢ Max: {pca_matrix.max():.6f}\")\n",
    "    print(f\"   ‚Ä¢ Mean: {pca_matrix.mean():.6f}\")\n",
    "    print(f\"   ‚Ä¢ Std: {pca_matrix.std():.6f}\")\n",
    "    print(f\"   ‚Ä¢ M√©diane: {np.median(pca_matrix):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_pca is not None and 'pca_array' in df_pca.columns:\n",
    "    # Statistiques par composante\n",
    "    print(\"\\nüìà Statistiques par composante principale:\")\n",
    "    pca_df_stats = pd.DataFrame({\n",
    "        'Composante': [f'PC{i+1}' for i in range(pca_matrix.shape[1])],\n",
    "        'Mean': pca_matrix.mean(axis=0),\n",
    "        'Std': pca_matrix.std(axis=0),\n",
    "        'Min': pca_matrix.min(axis=0),\n",
    "        'Max': pca_matrix.max(axis=0)\n",
    "    })\n",
    "    display(pca_df_stats.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Informations du mod√®le PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les informations du mod√®le PCA\n",
    "model_info_files = list(MODEL_INFO_DIR.glob('model_info_*/part-*.txt'))\n",
    "print(f\"üìÑ Fichiers model_info trouv√©s: {len(model_info_files)}\")\n",
    "\n",
    "if model_info_files:\n",
    "    # Lire tous les fichiers et concat√©ner\n",
    "    model_info_json = ''\n",
    "    for f in model_info_files:\n",
    "        with open(f, 'r') as file:\n",
    "            content = file.read().strip()\n",
    "            if content:  # Ignorer les fichiers vides\n",
    "                model_info_json += content\n",
    "    \n",
    "    if model_info_json:\n",
    "        model_info = json.loads(model_info_json)\n",
    "        print(f\"‚úÖ Informations du mod√®le charg√©es\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Tous les fichiers sont vides\")\n",
    "        model_info = None\n",
    "else:\n",
    "    print(\"‚ùå Aucun fichier model_info trouv√©\")\n",
    "    model_info = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_info:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ü§ñ INFORMATIONS DU MOD√àLE PCA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\n‚è∞ Timestamp: {model_info['timestamp']}\")\n",
    "    print(f\"üìä Composantes PCA: {model_info['pca_components']}\")\n",
    "    print(f\"üìê Dimensions originales: {model_info['original_dimensions']}\")\n",
    "    print(f\"üìâ Dimensions r√©duites: {model_info['reduced_dimensions']}\")\n",
    "    print(f\"üñºÔ∏è  Images trait√©es: {model_info['num_images_processed']:,}\")\n",
    "    print(f\"\\nüìà Variance totale expliqu√©e: {model_info['total_variance_explained']:.4f} ({model_info['total_variance_explained']*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nüìä Top 10 composantes principales:\")\n",
    "    for i in range(min(10, len(model_info['variance_by_component']))):\n",
    "        var = model_info['variance_by_component'][i]\n",
    "        cum_var = model_info['cumulative_variance'][i]\n",
    "        print(f\"   PC{i+1:2d}: {var:.6f} ({var*100:5.2f}%) | Cumul√©e: {cum_var:.6f} ({cum_var*100:5.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les donn√©es de variance depuis le CSV\n",
    "variance_files = list(MODEL_INFO_DIR.glob('variance_*/part-*.csv'))\n",
    "print(f\"üìÑ Fichiers variance trouv√©s: {len(variance_files)}\")\n",
    "\n",
    "if variance_files:\n",
    "    df_variance = pd.concat([pd.read_csv(f) for f in variance_files], ignore_index=True)\n",
    "    df_variance = df_variance.sort_values('component').reset_index(drop=True)\n",
    "    print(f\"‚úÖ Donn√©es de variance charg√©es: {len(df_variance)} composantes\")\n",
    "    display(df_variance.head(10))\n",
    "else:\n",
    "    print(\"‚ùå Aucun fichier de variance trouv√©\")\n",
    "    df_variance = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Variance expliqu√©e par composante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_variance is not None:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Graphique 1: Variance expliqu√©e par les 10 premi√®res composantes\n",
    "    top10 = df_variance.head(10)\n",
    "    ax1.bar(top10['component'], top10['variance_explained'], color='steelblue', edgecolor='black')\n",
    "    ax1.set_title('Variance expliqu√©e - Top 10 composantes', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Composante principale', fontsize=12)\n",
    "    ax1.set_ylabel('Variance expliqu√©e', fontsize=12)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    ax1.set_xticks(top10['component'])\n",
    "    \n",
    "    # Graphique 2: Variance cumul√©e pour toutes les composantes\n",
    "    ax2.plot(df_variance['component'], df_variance['cumulative_variance'], \n",
    "             marker='o', linewidth=2, markersize=4, color='darkgreen')\n",
    "    ax2.axhline(y=0.90, color='red', linestyle='--', label='90% variance')\n",
    "    ax2.axhline(y=0.95, color='orange', linestyle='--', label='95% variance')\n",
    "    ax2.set_title('Variance cumul√©e - Toutes les composantes', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Nombre de composantes', fontsize=12)\n",
    "    ax2.set_ylabel('Variance cumul√©e', fontsize=12)\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyse\n",
    "    n_90 = df_variance[df_variance['cumulative_variance'] >= 0.90]['component'].min()\n",
    "    n_95 = df_variance[df_variance['cumulative_variance'] >= 0.95]['component'].min()\n",
    "    n_99 = df_variance[df_variance['cumulative_variance'] >= 0.99]['component'].min()\n",
    "    \n",
    "    print(f\"\\nüìä Analyse de variance:\")\n",
    "    print(f\"   ‚Ä¢ {n_90} composantes pour capturer 90% de variance\")\n",
    "    print(f\"   ‚Ä¢ {n_95} composantes pour capturer 95% de variance\")\n",
    "    print(f\"   ‚Ä¢ {n_99 if not pd.isna(n_99) else 'N/A'} composantes pour capturer 99% de variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Projection 2D (PC1 vs PC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_pca is not None and 'pca_array' in df_pca.columns:\n",
    "    # Cr√©er un DataFrame avec PC1 et PC2\n",
    "    pca_2d = pd.DataFrame({\n",
    "        'PC1': [arr[0] for arr in df_pca['pca_array']],\n",
    "        'PC2': [arr[1] for arr in df_pca['pca_array']],\n",
    "        'label': df_pca['label']\n",
    "    })\n",
    "    \n",
    "    # Scatter plot 2D\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    # Cr√©er un scatter plot par classe\n",
    "    for label in pca_2d['label'].unique():\n",
    "        mask = pca_2d['label'] == label\n",
    "        ax.scatter(pca_2d.loc[mask, 'PC1'], \n",
    "                  pca_2d.loc[mask, 'PC2'],\n",
    "                  label=label, \n",
    "                  alpha=0.7, \n",
    "                  s=100,\n",
    "                  edgecolors='black',\n",
    "                  linewidths=0.5)\n",
    "    \n",
    "    ax.set_title('Projection PCA 2D (PC1 vs PC2) - Color√© par classe', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(f'PC1 ({df_variance.iloc[0][\"variance_explained\"]*100:.2f}% variance)', \n",
    "                 fontsize=12)\n",
    "    ax.set_ylabel(f'PC2 ({df_variance.iloc[1][\"variance_explained\"]*100:.2f}% variance)', \n",
    "                 fontsize=12)\n",
    "    ax.legend(title='Classe', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Statistiques de projection 2D:\")\n",
    "    print(f\"   ‚Ä¢ PC1 range: [{pca_2d['PC1'].min():.2f}, {pca_2d['PC1'].max():.2f}]\")\n",
    "    print(f\"   ‚Ä¢ PC2 range: [{pca_2d['PC2'].min():.2f}, {pca_2d['PC2'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Projection 3D (PC1, PC2, PC3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_pca is not None and 'pca_array' in df_pca.columns:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    # Cr√©er un DataFrame avec PC1, PC2 et PC3\n",
    "    pca_3d = pd.DataFrame({\n",
    "        'PC1': [arr[0] for arr in df_pca['pca_array']],\n",
    "        'PC2': [arr[1] for arr in df_pca['pca_array']],\n",
    "        'PC3': [arr[2] for arr in df_pca['pca_array']],\n",
    "        'label': df_pca['label']\n",
    "    })\n",
    "    \n",
    "    # Scatter plot 3D\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Cr√©er un scatter plot par classe\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, pca_3d['label'].nunique()))\n",
    "    for i, label in enumerate(pca_3d['label'].unique()):\n",
    "        mask = pca_3d['label'] == label\n",
    "        ax.scatter(pca_3d.loc[mask, 'PC1'], \n",
    "                  pca_3d.loc[mask, 'PC2'],\n",
    "                  pca_3d.loc[mask, 'PC3'],\n",
    "                  label=label,\n",
    "                  alpha=0.7,\n",
    "                  s=100,\n",
    "                  c=[colors[i]],\n",
    "                  edgecolors='black',\n",
    "                  linewidths=0.5)\n",
    "    \n",
    "    ax.set_title('Projection PCA 3D (PC1, PC2, PC3) - Color√© par classe', \n",
    "                fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel(f'PC1 ({df_variance.iloc[0][\"variance_explained\"]*100:.2f}%)', fontsize=10)\n",
    "    ax.set_ylabel(f'PC2 ({df_variance.iloc[1][\"variance_explained\"]*100:.2f}%)', fontsize=10)\n",
    "    ax.set_zlabel(f'PC3 ({df_variance.iloc[2][\"variance_explained\"]*100:.2f}%)', fontsize=10)\n",
    "    ax.legend(title='Classe', bbox_to_anchor=(1.15, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Statistiques de projection 3D:\")\n",
    "    print(f\"   ‚Ä¢ PC1 range: [{pca_3d['PC1'].min():.2f}, {pca_3d['PC1'].max():.2f}]\")\n",
    "    print(f\"   ‚Ä¢ PC2 range: [{pca_3d['PC2'].min():.2f}, {pca_3d['PC2'].max():.2f}]\")\n",
    "    print(f\"   ‚Ä¢ PC3 range: [{pca_3d['PC3'].min():.2f}, {pca_3d['PC3'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Distribution des valeurs PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_pca is not None and 'pca_array' in df_pca.columns:\n",
    "    # Cr√©er un DataFrame avec les 3 premi√®res composantes\n",
    "    pca_components = pd.DataFrame({\n",
    "        'PC1': [arr[0] for arr in df_pca['pca_array']],\n",
    "        'PC2': [arr[1] for arr in df_pca['pca_array']],\n",
    "        'PC3': [arr[2] for arr in df_pca['pca_array']]\n",
    "    })\n",
    "    \n",
    "    # Histogrammes des distributions\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    for i, (col, ax) in enumerate(zip(['PC1', 'PC2', 'PC3'], axes)):\n",
    "        ax.hist(pca_components[col], bins=30, color=f'C{i}', alpha=0.7, edgecolor='black')\n",
    "        ax.set_title(f'Distribution de {col}', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Valeur', fontsize=12)\n",
    "        ax.set_ylabel('Fr√©quence', fontsize=12)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Ajouter des statistiques\n",
    "        mean_val = pca_components[col].mean()\n",
    "        std_val = pca_components[col].std()\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "        ax.axvline(mean_val + std_val, color='orange', linestyle=':', linewidth=2, label=f'¬±1 Std: {std_val:.2f}')\n",
    "        ax.axvline(mean_val - std_val, color='orange', linestyle=':', linewidth=2)\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Boxplot des composantes principales par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_pca is not None and 'pca_array' in df_pca.columns:\n",
    "    # Cr√©er un DataFrame pour le boxplot\n",
    "    pca_boxplot = pd.DataFrame({\n",
    "        'PC1': [arr[0] for arr in df_pca['pca_array']],\n",
    "        'PC2': [arr[1] for arr in df_pca['pca_array']],\n",
    "        'PC3': [arr[2] for arr in df_pca['pca_array']],\n",
    "        'label': df_pca['label']\n",
    "    })\n",
    "    \n",
    "    # Boxplots par classe\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    for i, (col, ax) in enumerate(zip(['PC1', 'PC2', 'PC3'], axes)):\n",
    "        pca_boxplot.boxplot(column=col, by='label', ax=ax, grid=False)\n",
    "        ax.set_title(f'Distribution de {col} par classe', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Classe', fontsize=12)\n",
    "        ax.set_ylabel(f'{col} valeur', fontsize=12)\n",
    "        plt.sca(ax)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"üìù CONCLUSIONS - MODE MINI (300 images)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if model_info:\n",
    "    print(f\"\\n‚úÖ Pipeline ex√©cut√© avec succ√®s:\")\n",
    "    print(f\"   ‚Ä¢ {model_info['num_images_processed']} images trait√©es\")\n",
    "    print(f\"   ‚Ä¢ Extraction de features: MobileNetV2 (1280D)\")\n",
    "    print(f\"   ‚Ä¢ R√©duction PCA: 1280D ‚Üí 50D (96.1% compression)\")\n",
    "    print(f\"   ‚Ä¢ Variance totale pr√©serv√©e: {model_info['total_variance_explained']*100:.2f}%\")\n",
    "\n",
    "if df_metadata is not None:\n",
    "    print(f\"\\nüìä Donn√©es analys√©es:\")\n",
    "    print(f\"   ‚Ä¢ Nombre de classes: {df_metadata['label'].nunique()}\")\n",
    "    print(f\"   ‚Ä¢ Classes: {', '.join(df_metadata['label'].unique())}\")\n",
    "\n",
    "if df_variance is not None:\n",
    "    n_90 = df_variance[df_variance['cumulative_variance'] >= 0.90]['component'].min()\n",
    "    n_95 = df_variance[df_variance['cumulative_variance'] >= 0.95]['component'].min()\n",
    "    \n",
    "    print(f\"\\nüí° Insights cl√©s:\")\n",
    "    print(f\"   ‚Ä¢ Les 2 premi√®res composantes (PC1, PC2) capturent \"\n",
    "          f\"{df_variance.iloc[:2]['cumulative_variance'].max()*100:.2f}% de variance\")\n",
    "    print(f\"   ‚Ä¢ Seulement {n_90} composantes suffisent pour 90% de variance\")\n",
    "    print(f\"   ‚Ä¢ {n_95} composantes pour 95% de variance\")\n",
    "    print(f\"   ‚Ä¢ Les features PCA permettent une s√©paration visuelle des classes\")\n",
    "\n",
    "print(f\"\\nüöÄ Prochaines √©tapes:\")\n",
    "print(f\"   1. Ex√©cuter le pipeline en mode 'apples' (~6,400 images)\")\n",
    "print(f\"   2. Ex√©cuter le pipeline en mode 'full' (~67,000 images)\")\n",
    "print(f\"   3. Comparer les r√©sultats des 3 modes\")\n",
    "print(f\"   4. Entra√Æner un mod√®le de classification sur les features PCA\")\n",
    "print(f\"   5. √âvaluer la performance: PCA 50D vs features brutes 1280D\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
